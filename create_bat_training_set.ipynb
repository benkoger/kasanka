{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bat_functions as kbf\n",
    "# from bat_functions import process_frame, get_tracked_bats_in_frame, initialize_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_annotation_frame(info_dict):\n",
    "    \"\"\" Generate mask for image and save both.\n",
    "    \n",
    "    Args:\n",
    "        info_dict: dictionary that contains:\n",
    "            frame_files: list of frame files in clip\n",
    "            focal_frame: frame ind to process\n",
    "            save_folder: Path to folder to save images and masks\n",
    "            save_images: boolean should image and mask be saved\n",
    "    \"\"\"\n",
    "    frame_files = info_dict['frame_files']\n",
    "    focal_frame = info_dict['focal_frame']\n",
    "    save_folder = info_dict['save_folder']\n",
    "    save_images = info_dict['save_images']\n",
    "    return_result = info_dict['return_result']\n",
    "    \n",
    "    # index of focal_frame in images array\n",
    "    focal_frame_ind = 15\n",
    "    array_size = 31\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for file in frame_files[focal_frame-focal_frame_ind:array_size-focal_frame_ind+focal_frame]:\n",
    "        image = cv2.imread(file)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        images.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    images = np.stack(images)\n",
    "\n",
    "    background_sum = np.sum(images[:,:,:,2], 0, dtype=np.int16)\n",
    "\n",
    "    bat_thresh = .1\n",
    "    bat_area = 1\n",
    "\n",
    "    total_frames = len(frame_files)\n",
    "\n",
    "    bat_centers, bat_areas, bat_contours, rect_angles, bat_sizes, bat_rects, bat_thresh, binary = process_frame(\n",
    "        images, focal_frame_ind, bat_thresh, background_sum, bat_area, debug=True)\n",
    "\n",
    "    mask = np.zeros_like(binary, dtype=np.uint8)\n",
    "    mask = cv2.drawContours(mask, bat_contours, -1, 255, -1)\n",
    "\n",
    "    if save_images:\n",
    "        shutil.copy(frame_files[focal_frame], os.path.join(out_folder, 'images'))\n",
    "        mask_name = os.path.splitext(os.path.basename(frame_files[focal_frame]))[0]\n",
    "        mask_file = os.path.join(out_folder, 'masks', mask_name + '.png')\n",
    "        cv2.imwrite(mask_file, mask)\n",
    "        \n",
    "    if return_result:\n",
    "        return images[focal_frame_ind], mask\n",
    "    \n",
    "    \n",
    "def generate_annotation_frame_with_tracks(info_dict):\n",
    "    \"\"\" Generate mask for image and save both.\n",
    "    \n",
    "    Args:\n",
    "        info_dict: dictionary that contains:\n",
    "            frame_files: list of frame files in clip\n",
    "            focal_frame: frame ind to process\n",
    "            save_folder: Path to folder to save images and masks\n",
    "            save_images: boolean should image and mask be saved\n",
    "        \n",
    "    \"\"\"\n",
    "    frame_files = info_dict['frame_files']\n",
    "    focal_frame_ind = info_dict['focal_frame']\n",
    "    save_folder = info_dict['save_folder']\n",
    "    save_images = info_dict['save_images']\n",
    "    return_result = info_dict['return_result']\n",
    "    min_track_length = info_dict['min_track_length']\n",
    "    \n",
    "    if info_dict['annotation_num'] % 100 == 0:\n",
    "        print('annotation number {} started.'.format(info_dict['annotation_num']))\n",
    "    \n",
    "    bat_thresh = .1\n",
    "    bat_area_thresh = 1\n",
    " \n",
    "    track_list, positions = kbf.get_tracked_bats_in_frame(\n",
    "        frame_files, focal_frame_ind=focal_frame_ind, bat_thresh=bat_thresh, \n",
    "        bat_area_thresh=bat_area_thresh\n",
    "    )\n",
    "    ind = 0\n",
    "    \n",
    "    image = plt.imread(frame_files[focal_frame_ind + ind])\n",
    "    mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    \n",
    "    num_tracks_drawn = 0\n",
    "    num_short_tracks = 0\n",
    "    \n",
    "    for track in track_list:\n",
    "        if (track['first_frame'] <= ind and len(track['track']) >= min_track_length):\n",
    "            cnt = track['contour'][ind]\n",
    "            if not np.any(np.isnan(cnt)):\n",
    "                if len(track['track']) == 2:\n",
    "                    color = [255, 255, 255]\n",
    "                else:\n",
    "                    color = [255, 255, 255]\n",
    "                cv2.drawContours(mask, [cnt], 0, color, -1)\n",
    "                num_tracks_drawn += 1\n",
    "        if len(track['track']) == 2:\n",
    "            num_short_tracks += 1\n",
    "#     print('num tracks drawn: {} num short: {}'.format(num_tracks_drawn, num_short_tracks))            \n",
    "\n",
    "    if save_images:\n",
    "        shutil.copy(frame_files[focal_frame_ind], os.path.join(save_folder, 'images'))\n",
    "        mask_name = os.path.splitext(os.path.basename(frame_files[focal_frame_ind]))[0]\n",
    "        mask_file = os.path.join(save_folder, 'masks', mask_name + '.png')\n",
    "        cv2.imwrite(mask_file, mask)\n",
    "        \n",
    "    if return_result:\n",
    "        return image, mask\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_folder = '.../bats/18Nov/BBC/GH029844'\n",
    "image_folder_root = \".../Elements/bats/17Nov\"\n",
    "\n",
    "camera_files = sorted(glob.glob(os.path.join(image_folder_root, '*')))\n",
    "camera_names = [os.path.basename(file) for file in camera_files]\n",
    "print(camera_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = '.../kasanka-bats/annotations/test'\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "os.makedirs(os.path.join(out_folder, 'masks'), exist_ok=True)\n",
    "os.makedirs(os.path.join(out_folder, 'images'), exist_ok=True)\n",
    "\n",
    "image_folder_root = \".../Elements/bats/17Nov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_info_dict = {}\n",
    "\n",
    "annotation_info_dict['17'] = {\n",
    "    'BBC': {\"first_frame\": 5000, \"last_frame\": 15000, \"min_track_length\": 3},\n",
    "    'Chyniangale': {\"first_frame\": 15001, \"last_frame\": 26000, \"min_track_length\": 3},\n",
    "    'FibweParking2': {\"first_frame\": 19000, \"last_frame\": 34000, \"min_track_length\": 3},\n",
    "    'Fibwe_Public': {\"first_frame\": 25000, \"last_frame\": 35800, \"min_track_length\": 3},\n",
    "    'MusoleTower': {\"first_frame\": 28500, \"last_frame\": 45000, \"min_track_length\": 2},\n",
    "#     'Musole_Parking': {\"first_frame\": 30000, \"last_frame\": 40000, \"min_track_length\": 3},\n",
    "    'MusoleParking': {\"first_frame\": 40000, \"last_frame\": 60000, \"min_track_length\": 1},\n",
    "    'Musole_Path2': {\"first_frame\": 5000, \"last_frame\": 13000, \"min_track_length\": 3},\n",
    "    'NotChyniangale': {\"first_frame\": 3000, \"last_frame\": 15000, \"min_track_length\": 3},\n",
    "    'Puku': {\"first_frame\": 5500, \"last_frame\": 11500, \"min_track_length\": 3},\n",
    "    'Sunset': {\"first_frame\": None, \"last_frame\": None, \"min_track_length\": 3},\n",
    "}\n",
    "\n",
    "# annotation_info_dict['18'] = {'BBC': {\"first_frame\": None, \"last_frame\": None},\n",
    "#                               'Chyniangale': {\"first_frame\": None, \"last_frame\": None},\n",
    "#                               'FibweParking2': {\"first_frame\": 15000, \"last_frame\": 27000},\n",
    "#                               'Fibwe_Public': {\"first_frame\": 22000, \"last_frame\": 42000},\n",
    "#                               'MusoleTower': {\"first_frame\": 25000, \"last_frame\": 32000},\n",
    "#                               'Musole_Parking': {\"first_frame\": 30000, \"last_frame\": 40000},\n",
    "#                               'Musole_Path2': {\"first_frame\": 3000, \"last_frame\": 18000},\n",
    "#                               'NotChyniangale': {\"first_frame\": 2000, \"last_frame\": 12000},\n",
    "#                               'Puku': {\"first_frame\": None, \"last_frame\": None},\n",
    "#                               'Sunset': {\"first_frame\": None, \"last_frame\": None},\n",
    "#                              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_ind = 9\n",
    "\n",
    "camera_name = list(annotation_info_dict['17'].keys())[camera_ind]\n",
    "\n",
    "camera_name = \"MusoleParking\"\n",
    "\n",
    "frame_files = sorted(glob.glob(os.path.join(image_folder_root, camera_name, '*/*.jpg')))\n",
    "print(len(frame_files))\n",
    "print(frame_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View outputs\n",
    "\n",
    "random_inds = False # if false then pick evenly spaced\n",
    "num_frames = 5\n",
    "\n",
    "# camera_ind = 0\n",
    "# camera_name = list(annotation_info_dict['17'].keys())[camera_ind]\n",
    "\n",
    "info_dicts = []\n",
    "\n",
    "annotation_num = 0\n",
    "\n",
    "camera_name = 'MusoleParking'\n",
    "save_images = False\n",
    "show_images = True\n",
    "\n",
    "\n",
    "\n",
    "frame_files = sorted(glob.glob(os.path.join(image_folder_root, camera_name, '*/*.jpg')))\n",
    "\n",
    "print('There are {} frames'.format(len(frame_files)))\n",
    "print(frame_files[0])\n",
    "\n",
    "first_frame = annotation_info_dict['17'][camera_name]['first_frame']\n",
    "last_frame = annotation_info_dict['17'][camera_name]['last_frame']\n",
    "min_track_length = annotation_info_dict['17'][camera_name]['min_track_length']\n",
    "\n",
    "\n",
    "\n",
    "if (first_frame is not None) and (last_frame is not None):\n",
    "    if random_inds:\n",
    "        focal_frame_inds = np.random.randint(first_frame, last_frame, num_frames)\n",
    "    else:\n",
    "        focal_frame_inds = np.linspace(first_frame, last_frame, num_frames, dtype=int)\n",
    "\n",
    "\n",
    "    for focal_frame_ind in focal_frame_inds:\n",
    "\n",
    "        info_dict = {'frame_files': frame_files,\n",
    "                     'focal_frame': focal_frame_ind,\n",
    "                     'save_folder': out_folder,\n",
    "                     'save_images': save_images,\n",
    "                     'return_result': show_images,\n",
    "                     'min_track_length': min_track_length, \n",
    "                     'annotation_num': annotation_num\n",
    "                    }\n",
    "        info_dicts.append(info_dict)\n",
    "        annotation_num += 1\n",
    "print('{} dictionaries created'.format(len(info_dicts)))  \n",
    "\n",
    "for info_dict in info_dicts:\n",
    "    im, mask = generate_annotation_frame_with_tracks(info_dict)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(im)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    scaled_im = np.copy(im)\n",
    "    scaled_im -= np.min(scaled_im)\n",
    "    scaled_im = scaled_im / np.max(scaled_im)\n",
    "    plt.imshow(scaled_im)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_inds = True # if false then pick evenly spaced\n",
    "num_frames = 100\n",
    "\n",
    "# camera_ind = 0\n",
    "# camera_name = list(annotation_info_dict['17'].keys())[camera_ind]\n",
    "\n",
    "info_dicts = []\n",
    "\n",
    "annotation_num = 0\n",
    "\n",
    "for camera_name in annotation_info_dict['17']:\n",
    "\n",
    "    frame_files = sorted(glob.glob(os.path.join(image_folder_root, camera_name, '*/*.jpg')))\n",
    "\n",
    "    print('There are {} frames'.format(len(frame_files)))\n",
    "    print(frame_files[0])\n",
    "\n",
    "    first_frame = annotation_info_dict['17'][camera_name]['first_frame']\n",
    "    last_frame = annotation_info_dict['17'][camera_name]['last_frame']\n",
    "    min_track_length = annotation_info_dict['17'][camera_name]['min_track_length']\n",
    "\n",
    "    \n",
    "    \n",
    "    if (first_frame is not None) and (last_frame is not None):\n",
    "        if random_inds:\n",
    "            focal_frame_inds = np.random.randint(first_frame, last_frame, num_frames)\n",
    "        else:\n",
    "            focal_frame_inds = np.linspace(first_frame, last_frame, num_frames, dtype=int)\n",
    "                                      \n",
    "\n",
    "        for focal_frame_ind in focal_frame_inds:\n",
    "            save_images = True\n",
    "            show_images = False\n",
    "            info_dict = {'frame_files': frame_files,\n",
    "                         'focal_frame': focal_frame_ind,\n",
    "                         'save_folder': out_folder,\n",
    "                         'save_images': save_images,\n",
    "                         'return_result': show_images,\n",
    "                         'min_track_length': min_track_length, \n",
    "                         'annotation_num': annotation_num\n",
    "                        }\n",
    "            info_dicts.append(info_dict)\n",
    "            annotation_num += 1\n",
    "print('{} dictionaries created'.format(len(info_dicts)))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(7):\n",
    "    print(info_dicts[ind]['save_folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(7) as p:\n",
    "        p.map(generate_annotation_frame_with_tracks, info_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = generate_annotation_frame_with_tracks(info_dict)\n",
    "            if show_images:\n",
    "                plt.figure(figsize=(20, 20))\n",
    "                plt.imshow(image)\n",
    "                plt.imshow(mask, alpha=.3)\n",
    "                plt.title('Frame num {}'.format(focal_frame_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(5):\n",
    "    print(info_dicts[ind]['focal_frame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_frame_ind = 14900\n",
    "\n",
    "# out_folder = ' '\n",
    "save_images = False\n",
    "show_images = True\n",
    "info_dict = {'frame_files': frame_files,\n",
    "             'focal_frame': focal_frame_ind,\n",
    "             'save_folder': out_folder,\n",
    "             'save_images': save_images,\n",
    "             'return_result': show_images,\n",
    "             'min_track_length': 3\n",
    "            }\n",
    "info_dicts[0]['return_result'] = True\n",
    "image, mask = generate_annotation_frame_with_tracks(info_dicts[0])\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "plt.imshow(mask, alpha=.2)\n",
    "plt.title('Frame num {}'.format(focal_frame_ind))\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_dicts = []\n",
    "\n",
    "# for camera_ind, camera_name in enumerate(camera_names[:]):\n",
    "    \n",
    "#     first_frame = annotation_info_dict['17'][camera_name]['first_frame']\n",
    "#     last_frame = annotation_info_dict['17'][camera_name]['last_frame']\n",
    "    \n",
    "#     if first_frame is None or last_frame is None:\n",
    "#         continue\n",
    "        \n",
    "#     print(camera_name)\n",
    "    \n",
    "#     frame_files = sorted(glob.glob(os.path.join(camera_files[camera_ind], '*/*.jpg')))\n",
    "#     print(frame_files[0])\n",
    "\n",
    "#     frame_inds = np.linspace(first_frame, last_frame, num_images_per_camera, dtype=int)\n",
    "\n",
    "#     for num_frames, focal_ind in enumerate(frame_inds):\n",
    "\n",
    "#         info_dict = {'frame_files': frame_files,\n",
    "#                      'focal_frame': focal_ind,\n",
    "#                      'save_folder': out_folder,\n",
    "#                      'save_images': save_images,\n",
    "#                      'return_result': show_images\n",
    "#                     }\n",
    "\n",
    "#         info_dicts.append(info_dict)\n",
    "\n",
    "\n",
    "#         if show_images:\n",
    "#             image, mask = generate_annotation_frame(info_dict)\n",
    "#             plt.figure(figsize=(10, 10))\n",
    "#             plt.imshow(image)\n",
    "#             plt.figure(figsize=(10, 10))\n",
    "#             plt.imshow(mask)\n",
    "        \n",
    "# print('{} images are ready to be processed. Saving is set to {}'.format(len(info_dicts), save_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_files = glob.glob(image_folder + '/*.jpg')\n",
    "# image_files.sort()\n",
    "# print('There are {} frames'.format(len(frame_files)))\n",
    "\n",
    "\n",
    "# bat_thresh = .1\n",
    "# bat_area_thresh = 1\n",
    "# focal_frame_ind = 23999\n",
    "# track_list, positions = kbf.get_tracked_bats_in_frame(frame_files, focal_frame_ind=focal_frame_ind, \n",
    "#                                        bat_thresh=bat_thresh, \n",
    "#                                        bat_area_thresh=bat_area_thresh\n",
    "#                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_frames = [len(track['track']) for track in track_list if track['first_frame']==0]\n",
    "# plt.hist(first_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_list[0]['last_frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for track in track_list:\n",
    "#     if track['last_frame'] == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_scale=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = plt.imread(frame_files[focal_frame_ind])\n",
    "# plt.figure(figsize = (int(image.shape[1] / figure_scale), int(image.shape[0] / figure_scale)))\n",
    "# plt.imshow(image)\n",
    "# plt.scatter(positions[0][:,0], positions[0][:,1], c='red', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 1])\n",
    "print(bool(np.squeeze(x).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focal_frame_ind = 8333\n",
    "\n",
    "out_folder = ' '\n",
    "save_images = False\n",
    "show_images = True\n",
    "info_dict = {'frame_files': frame_files,\n",
    "             'focal_frame': focal_frame_ind,\n",
    "             'save_folder': out_folder,\n",
    "             'save_images': save_images,\n",
    "             'return_result': show_images\n",
    "            }\n",
    "image, mask = generate_annotation_frame_with_tracks(info_dict)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "# plt.figure(figsize=(20, 20))\n",
    "plt.imshow(mask, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_thresh = .1\n",
    "bat_area_thresh = 1\n",
    "# focal_frame_ind = 15000\n",
    "track_list, positions, distances, max_distances, active_list, all_pre_distances, all_row_inds, all_col_inds = kbf.get_tracked_bats_in_frame(frame_files, focal_frame_ind=focal_frame_ind, \n",
    "                                       bat_thresh=bat_thresh, \n",
    "                                       bat_area_thresh=bat_area_thresh\n",
    "                                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(distances[0][76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.argwhere(distances[0]==9.668213951199597))\n",
    "# print(np.argwhere(distances[0]==17.55639684181554))\n",
    "# print(distances[0][75, 37])\n",
    "# print(np.min(distances[0][:, 23]))\n",
    "\n",
    "# print(np.argwhere(all_pre_distances[0]==9.280355596635292))\n",
    "# print(all_pre_distances[0][75, 63])\n",
    "# print(np.min(all_pre_distances[0][:, 37]))\n",
    "\n",
    "# print(distances[0].shape, all_pre_distances[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos_ind, position in enumerate(positions[1]):\n",
    "    if (position[0] > 700) and (position[0] < 1000):\n",
    "        if (position[1] > 500) and (position[1] < 700):\n",
    "            print(pos_ind)\n",
    "            view_inds.append(track_ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_inds = []\n",
    "\n",
    "for track_ind, track in enumerate(track_list):\n",
    "    if (track['track'][0, 0] > 900) and (track['track'][0, 0] < 1100):\n",
    "        if (track['track'][0, 1] > 900) and (track['track'][0, 1] < 1100):\n",
    "            print(track_ind)\n",
    "            view_inds.append(track_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "r, c = linear_sum_assignment(distances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 75\n",
    "print(r[ind])\n",
    "print(np.min(distances[0][r[ind]]))\n",
    "print(np.argwhere(c==73))\n",
    "distances[0][r[ind], c[ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r[78])\n",
    "print(np.argmin(distances[0][r[78]]))\n",
    "print(np.argwhere(c==75))\n",
    "distances[0][r[78], c[78]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmin(distances[0][r[76]]))\n",
    "print(np.argwhere(c==74))\n",
    "distances[0][r[76], c[76]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_frame = 0\n",
    "focal_frame = 0 + first_frame\n",
    "figure_scale = 60\n",
    "\n",
    "max_ind = 1\n",
    "\n",
    "plt_ind = 266\n",
    "\n",
    "for focal_frame in range(0, 3):\n",
    "    num_drawn = 0\n",
    "    # for focal_frame in range(focal_frame - 2, focal_frame + 3, 2):\n",
    "    image = plt.imread(frame_files[focal_frame+focal_frame_ind])\n",
    "    images = [image]\n",
    "    mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    plt.figure(figsize = (int(images[0].shape[1] / figure_scale), int(images[0].shape[0] / figure_scale)))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    plt.scatter(positions[focal_frame-first_frame][:, 0], \n",
    "                positions[focal_frame-first_frame][:, 1], c='white', alpha=.5, s=50)\n",
    "    \n",
    "    for track_ind, track in enumerate(track_list):\n",
    "        if (track['last_frame'] >= focal_frame-first_frame \n",
    "            and track['first_frame'] <= focal_frame-first_frame\n",
    "           and len(track['track']) >= 1):\n",
    "            if track_ind in view_inds or False:\n",
    "                rel_frame = focal_frame - track['first_frame'] - first_frame\n",
    "                plt.plot(track['track'][:rel_frame, 0], track['track'][:rel_frame, 1], linewidth=2)\n",
    "                num_drawn += 1\n",
    "                if len(track['track']) == 2:\n",
    "                    color = 'red'\n",
    "                elif len(track['track']) == 3:\n",
    "                    color = 'yellow'\n",
    "                else:\n",
    "                    color = 'green'\n",
    "\n",
    "                plt.scatter(track['track'][rel_frame, 0], track['track'][rel_frame, 1], s=25, c=color)\n",
    "                cnt = track['contour'][rel_frame]\n",
    "                if not np.any(np.isnan(cnt)):\n",
    "                    try:\n",
    "                        cv2.drawContours(mask, [cnt], 0, 255, -1)\n",
    "                    except:\n",
    "                        print(cnt, cnt==np.nan)\n",
    "\n",
    "    \n",
    "#     plt.scatter(positions[focal_frame-first_frame][201,0], \n",
    "#                 positions[focal_frame-first_frame][201,1], c='red', alpha=.5, s=100)\n",
    "#     plt.scatter(positions[focal_frame-first_frame][:,0], \n",
    "#                 positions[focal_frame-first_frame][:,1], c='red', alpha=.5, s=20)\n",
    "#     plt.scatter(positions[focal_frame-first_frame][plt_args,0], \n",
    "#             positions[focal_frame-first_frame][plt_args,1], c='red', alpha=.5, s=20)\n",
    "    \n",
    "#     plt.scatter(positions[focal_frame+1-first_frame][:max_ind,0], positions[focal_frame+1-first_frame][:max_ind,1], c='green', alpha=.5)\n",
    "#     plt.figure(figsize = (int(images[0].shape[1] / figure_scale), int(images[0].shape[0] / figure_scale)))\n",
    "    plt.imshow(mask, alpha=.3)\n",
    "    print(num_drawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread(image_files[focal_frame_ind])\n",
    "plt.imshow(image)\n",
    "for track in tracks:\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = [len(track['size']) for track in tracks]\n",
    "plt.hist(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in track_list[:3]:\n",
    "    plt.scatter(track['track'][:,0], track['track'][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {'frame_files': frame_files,\n",
    "             'focal_frame': focal_ind,\n",
    "             'save_folder': out_folder,\n",
    "             'save_images': False,\n",
    "             'return_result': True\n",
    "            }\n",
    "\n",
    "image, mask = generate_annotation_frame_with_tracks(info_dict)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_ind = 12000\n",
    "\n",
    "info_dict = {'frame_files': frame_files,\n",
    "             'focal_frame': focal_ind,\n",
    "             'save_folder': out_folder,\n",
    "             'save_images': False,\n",
    "             'return_result': True\n",
    "            }\n",
    "\n",
    "image, mask = generate_annotation_frame(info_dict)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(5000, 15000, 2, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = []\n",
    "training_masks = []\n",
    "\n",
    "save_images = True\n",
    "show_images = False\n",
    "\n",
    "num_images_per_camera = 200\n",
    "max_folder_ind = 0\n",
    "first_frame = 15000\n",
    "last_frame = 27000\n",
    "\n",
    "show_every_n_images = 20\n",
    "\n",
    "info_dicts = []\n",
    "\n",
    "for camera_ind, camera_name in enumerate(camera_names[:1]):\n",
    "    \n",
    "    first_frame = annotation_info_dict['17'][camera_name]['first_frame']\n",
    "    last_frame = annotation_info_dict['17'][camera_name]['last_frame']\n",
    "    \n",
    "    if first_frame is None or last_frame is None:\n",
    "        continue\n",
    "        \n",
    "    print(camera_name)\n",
    "    \n",
    "    frame_files = sorted(glob.glob(os.path.join(camera_files[camera_ind], '*/*.jpg')))\n",
    "    print(frame_files[0])\n",
    "\n",
    "    frame_inds = np.linspace(first_frame, last_frame, num_images_per_camera, dtype=int)\n",
    "\n",
    "    for num_frames, focal_ind in enumerate(frame_inds):\n",
    "\n",
    "        info_dict = {'frame_files': frame_files,\n",
    "                     'focal_frame': focal_ind,\n",
    "                     'save_folder': out_folder,\n",
    "                     'save_images': save_images,\n",
    "                     'return_result': show_images\n",
    "                    }\n",
    "\n",
    "        info_dicts.append(info_dict)\n",
    "\n",
    "\n",
    "        if show_images:\n",
    "            image, mask = generate_annotation_frame(info_dict)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(image)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(mask)\n",
    "        \n",
    "print('{} images are ready to be processed. Saving is set to {}'.format(len(info_dicts), save_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(7) as p:\n",
    "        p.map(generate_annotation_frame, info_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(images):\n",
    "    \"\"\"Computer mean of each color channel from a list of images.\n",
    "    \n",
    "    Args:\n",
    "        images: list of 3D numpy array HWC\n",
    "    Returns:\n",
    "        [mean red, mean green, mean blue]\n",
    "    \"\"\"\n",
    "    color_sums = np.zeros(3)\n",
    "    total_pixels = 0\n",
    "    for image in images:\n",
    "        color_sums += np.sum(np.sum(image, 0), 0)\n",
    "        total_pixels += image.shape[0] * image.shape[1]\n",
    "    return color_sums / total_pixels\n",
    "        \n",
    "def compute_std(images):\n",
    "    \"\"\"Computer standard deviation of each color channel from a list of images.\n",
    "    \n",
    "    Args:\n",
    "        images: list of 3D numpy array HWC\n",
    "    Returns:\n",
    "        [std red, std green, std blue]\n",
    "    \"\"\"\n",
    "    \n",
    "    color_dif_sums = np.zeros(3)\n",
    "    total_pixels = 0\n",
    "    for image in images:\n",
    "        color_means = np.mean(np.mean(image, 0), 0)\n",
    "        dif = image - color_means\n",
    "        dif2 = dif ** 2\n",
    "        color_dif_sums += np.sum(np.sum(dif2, 0), 0)\n",
    "        total_pixels += image.shape[0] * image.shape[1]\n",
    "    std = np.sqrt(color_dif_sums / (total_pixels-1))\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(out_folder, 'data/mean.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = compute_mean(training_images)\n",
    "std = compute_std(training_images)\n",
    "\n",
    "print('mean', mean, 'std', std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(out_folder, 'mean.npy'), mean[::-1])\n",
    "np.save(os.path.join(out_folder, 'std.npy'), std[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files  = sorted(glob.glob(os.path.join(out_folder, 'images/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = [cv2.imread(file) for file in image_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(training_images[-1])\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(training_masks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
