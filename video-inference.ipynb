{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torch.utils.data import IterableDataset\n",
    "# from torchvision.datasets.video_utils import VideoClips\n",
    "from video_clip import VideoClips\n",
    "import torch.utils.data as data\n",
    "from bat_seg_models import ThreeLayerSemSegNetWideView, UNET, UNETTraditional\n",
    "from frame_augmentors import MaskNormalize, Mask3dto2d, AddDim, ToFloat, MaskCompose, MaskToTensor\n",
    "import bat_functions\n",
    "from CountLine import CountLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im_file = \".../kasanka-bats/frames/17Nov/card-f/GP039791/GP039791_15948.jpg\"\n",
    "im = plt.imread(im_file)\n",
    "\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_output_folder = '.../kasanka-bats/processed/deep-learning/corrected_model'\n",
    "date = '16Nov'\n",
    "os.makedirs(root_output_folder, exist_ok=True)\n",
    "\n",
    "raw_camera_folders = sorted(glob.glob('.../kasanka-bats/gopros/{}/*'.format(date)))\n",
    "\n",
    "camera_folders = []\n",
    "for camera_folder in raw_camera_folders:\n",
    "    videos = sorted(glob.glob(os.path.join(camera_folder, '*.[Mm][Pp]4')))\n",
    "    camera_name = camera_folder.split('/')[-1]\n",
    "    if not os.path.exists(os.path.join(root_output_folder, date, camera_name, 'centers.npy')):\n",
    "        print(*videos, sep='\\n')\n",
    "        print('--------------')\n",
    "        camera_folders.append(camera_folder)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatIterableDataset(IterableDataset):\n",
    "    def __init__(self, video_files, augmentor=None, max_bad_reads=300):\n",
    "        self.vid_cap = cv2.VideoCapture(video_files[0])\n",
    "        self.video_files = video_files\n",
    "        assert self.vid_cap.isOpened()\n",
    "        self.more_frames = True\n",
    "        # How many times a frame can come up false \n",
    "        # before assuming end of video\n",
    "        self.max_bad_reads = max_bad_reads\n",
    "        self.total_frames_read = 0\n",
    "        self.total_bad_reads = 0\n",
    "        self.augmentor = augmentor\n",
    "        self.video_number = 0\n",
    "        \n",
    "    def more_videos(self):\n",
    "        return self.video_number < len(self.video_files)\n",
    "    \n",
    "    def start_next_video(self):\n",
    "        if self.vid_cap.isOpened():\n",
    "            self.vid_cap.release()\n",
    "        self.video_number += 1\n",
    "        if self.video_number < len(self.video_files):\n",
    "            print('starting new video')\n",
    "            print(self.get_read_frame_info())\n",
    "            self.vid_cap = cv2.VideoCapture(self.video_files[self.video_number])\n",
    "        \n",
    "    def video_generator(self):\n",
    "        while(self.vid_cap.isOpened() or self.more_videos()):\n",
    "            if not self.vid_cap.isOpened():\n",
    "                self.start_next_video()\n",
    "            good_read = False\n",
    "            num_bad_reads = 0\n",
    "            while (not good_read and (num_bad_reads < self.max_bad_reads)):\n",
    "                grabbed, frame = self.vid_cap.read()\n",
    "                if grabbed:\n",
    "                    good_read = True\n",
    "                    self.total_frames_read += 1\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    frame = {'image': frame[2:-2, 2:-2]}\n",
    "                    if np.mean(frame['image'][::50,::50, 2]) < 5:\n",
    "                        print('too dark')\n",
    "                        self.vid_cap.release()\n",
    "                        break\n",
    "                        \n",
    "                    if self.augmentor:\n",
    "                        frame = self.augmentor(frame)\n",
    "                    yield frame\n",
    "                else:\n",
    "                    num_bad_reads += 1\n",
    "                    self.total_bad_reads += 1\n",
    "            if not good_read:\n",
    "                self.vid_cap.release()\n",
    "                print(\"video capture closed\")\n",
    "            \n",
    "    def __iter__(self):\n",
    "        return self.video_generator()\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self.vid_cap.isOpened():\n",
    "            self.vid_cap.release()\n",
    "    \n",
    "    def is_more_frames(self):\n",
    "        return self.vid_cap.isOpened()\n",
    "    \n",
    "    def get_read_frame_info(self):\n",
    "        print('{} frames have been read with {} bad reads'.format(self.total_frames_read,\n",
    "                                                                  self.total_bad_reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './models'\n",
    "\n",
    "# model_filename = 'model_ThreeLayerWide_epochs_10_batcheff_4_lr_0.05_momentum_0.5_aug_aug-no-blur-2d-17Nov-big-dataset.tar'\n",
    "model_filename = 'model_UNET_epochs_100_batcheff_16_lr_0.01_momentum_0.9_aug_aug-2d-20Nov-big-dataset.tar'\n",
    "model_filename = 'model_UNET_epochs_100_batcheff_16_lr_0.01_momentum_0.9_aug_better-norm-aug-2d-20Nov-big-dataset.tar'\n",
    "model_file = os.path.join(folder, model_filename)\n",
    "model_file = './models/model_UNETTraditional_epochs_100_batcheff_16_lr_0.01_momentum_0.9_aug_better-norm-aug-2d-20Nov-big-dataset.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_train_folder = \".../kasanka-bats/annotations\"\n",
    "mean = np.load(os.path.join(root_train_folder, 'mean.npy'))\n",
    "std = np.load(os.path.join(root_train_folder, 'std.npy'))\n",
    "\n",
    "channel = 2\n",
    "       \n",
    "    \n",
    "\n",
    "# augmentor = None\n",
    "bat_datasets = []\n",
    "for camera_folder in camera_folders:\n",
    "    videos = sorted(glob.glob(os.path.join(camera_folder, '*.[Mm][Pp]4')))\n",
    "    augmentor = MaskCompose([Mask3dto2d(channel_to_use=channel),\n",
    "                         MaskToTensor(),\n",
    "                         MaskNormalize(mean[channel]/255, std[channel]/255),\n",
    "                        ])\n",
    "    bat_dataset = BatIterableDataset(videos, augmentor=augmentor)\n",
    "    save_folder = os.path.join(root_output_folder, *camera_folder.split('/')[-2:])\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_folder, 'example-frames'), exist_ok=True)\n",
    "    bat_datasets.append({'dataset':bat_dataset,\n",
    "                         'save_folder': save_folder})\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bat_datasets[0]['dataset']:\n",
    "    break\n",
    "# dataloader = data.DataLoader(bat_dataset['dataset'], \n",
    "#                                  batch_size=batch_size,\n",
    "#                                  shuffle=False, num_workers=0, \n",
    "#                                  pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "# plt.imshow(((np.squeeze(i['image']) - mean) / std)[:,:,1])\n",
    "plt.imshow(np.squeeze(i['image']))\n",
    "plt.colorbar()\n",
    "# plt.figure(figsize=(20,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit2prob(logit):\n",
    "    e_l = np.e ** logit\n",
    "    return e_l \n",
    "\n",
    "def denorm_image(im, mean, std):\n",
    "    \"\"\" Take image the was normalized and return to 0 to 255\"\"\"\n",
    "#     im = np.copy(im)\n",
    "    im *= std\n",
    "    im += mean\n",
    "    im *= 255\n",
    "    im = np.maximum(im, 0)\n",
    "    im = np.minimum(im, 255)\n",
    "    im = im.astype(np.uint8)\n",
    "    \n",
    "    return im\n",
    "\n",
    "should_plot = False\n",
    "should_save = True\n",
    "\n",
    "num_classes = 2\n",
    "bat_prob_thresh = .6\n",
    "batch_size = 2\n",
    "early_stop = None\n",
    "# save some original frames to check detection quality\n",
    "save_every_n_frames = 1350\n",
    "channel = 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = UNETTraditional(1, 2, should_pad=False)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.to(device)\n",
    "\n",
    "model.train(False)\n",
    "\n",
    "for bat_dataset in bat_datasets[:]:\n",
    "\n",
    "    num_frames = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    print(bat_dataset['save_folder'])\n",
    "\n",
    "    dataloader = data.DataLoader(bat_dataset['dataset'], \n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False, num_workers=0, \n",
    "                                 pin_memory=True)\n",
    "\n",
    "    centers_list = []\n",
    "    contours_list = []\n",
    "    sizes_list = []\n",
    "    rects_list = []\n",
    "\n",
    "\n",
    "    for batch_ind, batch in enumerate(dataloader):\n",
    "        if batch_ind == 0:\n",
    "            print('started...')\n",
    "            t0 = time.time()\n",
    "        if early_stop:\n",
    "            if batch_ind >= early_stop:\n",
    "                break\n",
    "\n",
    "        im_batch = batch['image'].cuda()\n",
    "    #     masks = batch['mask'].cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(im_batch)\n",
    "            masks = (outputs[:, 1].cpu().numpy() > np.log(bat_prob_thresh)).astype(np.uint8)\n",
    "            \n",
    "            for ind, mask in enumerate(masks):\n",
    "                centers, areas, contours, _, _, rects = bat_functions.get_blob_info(mask)\n",
    "                centers_list.append(centers)\n",
    "                sizes_list.append(areas)\n",
    "                contours_list.append(contours)\n",
    "                rects_list.append(rects)\n",
    "                if save_every_n_frames:\n",
    "                    if num_frames % save_every_n_frames == 0:\n",
    "                        day = bat_dataset['save_folder'].split('/')[-2]\n",
    "                        card = bat_dataset['save_folder'].split('/')[-1]\n",
    "                        im_name = '{}_{}_obs-ind_{}.jpg'.format(day, card, num_frames)\n",
    "                        im_file = os.path.join(bat_dataset['save_folder'], \n",
    "                                               'example-frames', im_name)\n",
    "                        im = np.squeeze(batch['image'][ind].numpy())\n",
    "                        im = denorm_image(im, mean[channel]/255, std[channel]/255)\n",
    "                        cv2.imwrite(im_file, im)\n",
    "                num_frames += 1\n",
    "\n",
    "\n",
    "        if should_plot:\n",
    "            for ind in range(len(im_batch)):\n",
    "\n",
    "                if 'orig' in batch.keys():\n",
    "                    plt.figure(figsize=(10,10))\n",
    "                    plt.imshow(batch['orig'][ind])\n",
    "                plt.figure(figsize=(10,10))\n",
    "                im = im_batch[ind].cpu().numpy()\n",
    "                im = np.transpose(im, (1, 2, 0))\n",
    "                plt.imshow(im)\n",
    "                plt.figure(figsize=(10,10))\n",
    "                im = outputs[ind][0].cpu().numpy()\n",
    "                plt.imshow(im)\n",
    "                plt.title('output')\n",
    "                prob = logit2prob(outputs[ind,1].cpu().numpy())\n",
    "                mask = (prob > 0.5).astype(np.uint8)\n",
    "\n",
    "    #             display_im = np.zeros_like(im)\n",
    "    #             display_im[..., 0] = masks[ind]\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(mask)\n",
    "    #             plt.colorbar()\n",
    "    #             plt.figure(figsize=(10,10))\n",
    "    #             plt.imshow(display_im)\n",
    "\n",
    "    total_time = time.time() - t0\n",
    "    print(total_time, total_time / batch_ind / batch_size)\n",
    "    print(bat_dataset['dataset'].get_read_frame_info())\n",
    "    if should_save:\n",
    "        save_folder = bat_dataset['save_folder']\n",
    "        num_contour_files = 15\n",
    "        file_num = 0\n",
    "        new_contours = []\n",
    "        for frame_ind, cs in enumerate(contours_list):\n",
    "            if frame_ind % int(len(contours_list)/num_contour_files) == 0:\n",
    "                # start new file\n",
    "                file_name = f'contours-compressed-{file_num:02d}.npy'\n",
    "                file = os.path.join(save_folder, file_name)\n",
    "                np.save(file, np.array(new_contours, dtype=object))\n",
    "                new_contours = []\n",
    "                file_num += 1\n",
    "            new_contours.append([])\n",
    "            for c in cs:\n",
    "                cc\t= np.squeeze(cv2.approxPolyDP(c, 0.1, closed=True))\n",
    "                new_contours[-1].append(cc)\n",
    "        file_name = f'contours-compressed-{file_num:02d}.npy'\n",
    "        file = os.path.join(save_folder, file_name)\n",
    "        np.save(file, np.array(new_contours, dtype=object))\n",
    "#         np.save(os.path.join(save_folder, 'contours.npy'), contours_list)\n",
    "        np.save(os.path.join(save_folder, 'size.npy'), sizes_list)\n",
    "        np.save(os.path.join(save_folder,'rects.npy'), rects_list)\n",
    "        np.save(os.path.join(save_folder, 'centers.npy'), centers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(contours_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "im = plt.imread('.../kasanka-bats/processed/deep-learning/19Nov/BBC/example-frames/19Nov_BBC_obs-ind_0.jpg')\n",
    "plt.imshow(im, vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(contours[50000])/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_folder = \".../kasanka-bats/processed/deep-learning\"\n",
    "day = \"18Nov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_folders = glob.glob(os.path.join(track_folder, day, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs_ind_from_file(elem):\n",
    "    return int(elem.split('_')[-1].split('.')[0])\n",
    "\n",
    "for camera_folder in camera_folders[:1]:\n",
    "    contours = np.load(os.path.join(camera_folder, 'contours.npy'), allow_pickle=True)\n",
    "#     centers = np.load(os.path.join(camera_folder, 'centers.npy'), allow_pickle=True)\n",
    "#     rects = np.load(os.path.join(camera_folder, 'rects.npy'), allow_pickle=True)\n",
    "#     sizes = np.load(os.path.join(camera_folder, 'size.npy'), allow_pickle=True)\n",
    "#     frame_folder = os.path.join(camera_folder, 'example-frames')\n",
    "#     frame_files = sorted(glob.glob(os.path.join(frame_folder, '*.jpg')), key=get_obs_ind_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [len(s) for s in sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_frame_ind = 30\n",
    "obs_ind = frame_files[example_frame_ind].split('_')[-1].split('.')[0]\n",
    "plt.figure(figsize=(20,20))\n",
    "im = plt.imread(frame_files[example_frame_ind])\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers[1000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours_test = np.copy(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, (c, c_test) in enumerate(zip(contours, contours_test)):\n",
    "    assert(len(c) == len(c_test)), print(ind) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contours_test[15001]), len(contours[15001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = sorted(glob.glob('.../bats/17Nov/Chyniangale/*/*.jpg'))\n",
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(centers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ind = 0\n",
    "for ind, (con, cent, rect, size) in enumerate(zip(contours[start_ind:], centers[start_ind:], rects[start_ind:], sizes[start_ind:])):\n",
    "    lengths = [len(con), len(cent), len(rect), len(size)]\n",
    "    if not np.all(np.array(lengths) == len(con)):\n",
    "        print('error', ind, lengths)\n",
    "    if ind == 50000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(contours[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ind = 15000\n",
    "frame = plt.imread(frames[frame_ind])\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(frame)\n",
    "for position in centers[frame_ind]:\n",
    "    plt.scatter(position[0], position[1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(list_test, array_test):\n",
    "    l = list_test\n",
    "    l = l[:4]\n",
    "    a = array_test\n",
    "    a = a[:4]\n",
    "    \n",
    "    print(a)\n",
    "    \n",
    "list_example = [0, 1, 2, 3, 4, 5, 6]\n",
    "array_example = np.array([0, 1, 2, 3, 4 ,5, 6])\n",
    "\n",
    "test(list_example, array_example)\n",
    "print(list_example)\n",
    "print(array_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frame = 60000\n",
    "first_frame = 100\n",
    "t0 = time.time()\n",
    "tracks_list= bat_functions.find_tracks(first_frame, centers, contours, sizes, max_frame=max_frame)\n",
    "total_time = time.time() - t0\n",
    "print('total time: {}, fps: {}'.format(total_time, (max_frame - first_frame)/total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tracks(detection_dict):\n",
    "    centers = detection_dict['centers']\n",
    "    contours = detection_dict['contours']\n",
    "    sizes = detection_dict['sizes']\n",
    "    max_frame = detection_dict['max_frame']\n",
    "    save_file = detection_dict['save_file']\n",
    "    t0 = time.time()\n",
    "    tracks_list = bat_functions.find_tracks(0, centers, contours, sizes, max_frame=max_frame)\n",
    "    np.\n",
    "    total_time = time.time() - t0\n",
    "    print('total time: {}, fps: {}'.format(total_time, (max_frame - first_frame)/total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = '.../kasanka-bats/processed/17Nov/Chyniangale/GH040006/GH040006_new03-9500-rects.jpg'\n",
    "images = [plt.imread(image_file)]\n",
    "\n",
    "middle_line = CountLine(int(images[0].shape[0]/2), total_frames=max_frame)\n",
    "\n",
    "forward_size = []\n",
    "forward_mean_size = []\n",
    "time_forward = []\n",
    "backward_size = []\n",
    "backward_mean_size = []\n",
    "time_backward = []\n",
    "\n",
    "\n",
    "for track_ind, track in enumerate(tracks_list[:]):\n",
    "    result, frame_num = middle_line.is_crossing(track, track_ind)\n",
    "    if result == 1:\n",
    "        tracks_list[track_ind]['crossed'] = frame_num\n",
    "        forward_size.append(tracks_list[track_ind]['size'])\n",
    "        forward_mean_size.append(np.nanmean(tracks_list[track_ind]['size']))\n",
    "        time_forward.append(frame_num)\n",
    "    elif result == -1:\n",
    "        tracks_list[track_ind]['crossed'] = -frame_num\n",
    "        backward_size.append(tracks_list[track_ind]['size'])\n",
    "        backward_mean_size.append(np.nanmean(tracks_list[track_ind]['size']))\n",
    "        time_backward.append(frame_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(camera_folder, 'test_tracks.npy'), tracks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(max_frame-first_frame), np.cumsum(middle_line.num_crossing[first_frame:max_frame]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ind = 241\n",
    "plt.plot(forward_size[track_ind])\n",
    "plt.plot(np.ones(len(forward_size[track_ind]))*forward_mean_size[track_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(forward_size)\n",
    "plt.plot(forward_size[0])\n",
    "plt.plot(np.ones(len(forward_size[0]))*forward_mean_size[0])\n",
    "plt.figure()\n",
    "plt.hist(forward_mean_size, label='leaving bats')\n",
    "\n",
    "plt.hist(backward_mean_size, label='coming bats')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(time_forward, forward_mean_size)\n",
    "plt.scatter(time_backward, backward_mean_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "frames = []\n",
    "max_frames = 250\n",
    "\n",
    "for frame_ind, frame in enumerate(train_dataloader):\n",
    "    if frame_ind == 0:\n",
    "        print('starting')\n",
    "    frames.append(frame)\n",
    "    if frame_ind > max_frames:\n",
    "        break\n",
    "total_time = time.time() - t0\n",
    "print(total_time, total_time/max_frames, len(frames))\n",
    "print(bat_dataset.total_frames_read, bat_dataset.total_bad_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[-1])\n",
    "plt.figure()\n",
    "plt.imshow(frames[0] - frames[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(videos[0], cv2.CAP_FFMPEG)\n",
    "t0 = time.time()\n",
    "\n",
    "frame_count = 0\n",
    "max_frames = 100\n",
    "frames = []\n",
    "\n",
    "while(True):\n",
    "    if frame_count > max_frames:\n",
    "        break\n",
    "    # Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "    frames.append(frame)\n",
    "    ret = cap.grab()\n",
    "#     ret, frame = cap.retrieve()\n",
    "    frame_count += 1\n",
    "#     plt.figure()\n",
    "#     print(type(frame))\n",
    "#     plt.imshow(np.array(frame))\n",
    "\n",
    "#     # Our operations on the frame come here\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Display the resulting frame\n",
    "#     cv2.imshow('frame',gray)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "total_time = time.time() - t0\n",
    "print(total_time, total_time / len(frames), 'frames: {}'.format(len(frames)))\n",
    "\n",
    "print()\n",
    "# When everything done, release the capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with av.open(filename, metadata_errors=\"ignore\") as container:\n",
    "    if container.streams.video:\n",
    "        video_frames = _read_from_stream(\n",
    "            container,\n",
    "            start_pts,\n",
    "            end_pts,\n",
    "            pts_unit,\n",
    "            container.streams.video[0],\n",
    "            {\"video\": 0},\n",
    "        )\n",
    "        video_fps = container.streams.video[0].average_rate\n",
    "        # guard against potentially corrupted files\n",
    "        if video_fps is not None:\n",
    "            info[\"video_fps\"] = float(video_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatInferenceDataset(VisionDataset):\n",
    "    \"\"\" Dataset for running inference on bat videos.\n",
    "    \n",
    "    Args:\n",
    "        root (string): Root directory of the videos.\n",
    "        batch_size (int): number of frames to include in batch.\n",
    "        transform (callable, optional): A function/transform that takes in a TxHxWxC video\n",
    "            and returns a transformed version.\n",
    "\n",
    "    Returns:\n",
    "        video (Tensor[T, H, W, C]): the `T` video frames\n",
    "        video_idx (int): the index of the video the clip is from\n",
    "        clip_idx (int): the index of the video clip\"\"\"\n",
    "    \n",
    "    def __init__(self, root, batch_size, frame_rate=None, transform=None, num_workers=1):\n",
    "\n",
    "        video_paths = glob.glob('./*.mp4')\n",
    "        print('num workers', num_workers)\n",
    "        print(video_paths)\n",
    "\n",
    "        video_clips = VideoClips(\n",
    "            video_paths,\n",
    "            batch_size,\n",
    "            frames_between_clips=1,\n",
    "            frame_rate=frame_rate,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        self.video_clips_metadata = video_clips.metadata\n",
    "        self.transform = transform\n",
    "        self.video_clips = video_clips\n",
    "        \n",
    "    @property\n",
    "    def metadata(self):\n",
    "        return self.video_clips_metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.video_clips.num_clips()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video, audio, _, video_idx = self.video_clips.get_clip(idx)\n",
    "        \n",
    "        item = {'image': video, 'video_idx': video_idx, 'idx': idx}\n",
    "\n",
    "        if self.transform is not None:\n",
    "            item = self.transform(item)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_dataset.video_clips.get_clip(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.load(os.path.join(root_train_folder, 'mean.npy'))\n",
    "# std = np.load(os.path.join(root_train_folder, 'std.npy'))\n",
    "\n",
    "folder = './models'\n",
    "\n",
    "model_filename = 'model_ThreeLayerWide_epochs_10_batcheff_4_lr_0.05_momentum_0.5_aug_aug-no-blur-2d-17Nov-big-dataset.tar'\n",
    "model_file = os.path.join(folder, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '.../kasanka-bats/gopros/17Nov/card-b'\n",
    "folder = \".\"\n",
    "videos = glob.glob(os.path.join(folder, '*.mp4'))\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "clips = VideoClips(videos, 4, frames_between_clips=1, \n",
    "                   frame_rate=None,num_workers=7)\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_opencv(filename):\n",
    "    import cv2\n",
    "    video = cv2.VideoCapture(filename)\n",
    "\n",
    "    duration = video.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    return duration, frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "video_path = \".\"\n",
    "batch_size = 4\n",
    "frame_rate = 30\n",
    "num_workers = 0\n",
    "\n",
    "transforms = MaskCompose([Transform3dto2d(channel_to_use=2),\n",
    "                          AddDim(new_dim=1),\n",
    "                          ToFloat()\n",
    "                         ])\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "test_dataset = BatInferenceDataset(video_path, batch_size, frame_rate, \n",
    "                                   transform=transforms,\n",
    "                                   num_workers=num_workers\n",
    "                                  )\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(test_dataset, batch_size=None,\n",
    "                                   shuffle=False, num_workers=7, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(train_dataloader):\n",
    "    print(idx)\n",
    "    if idx > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item['image'].shape\n",
    "# item['image'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit2prob(logit):\n",
    "    e_l = np.e ** logit\n",
    "    return e_l \n",
    "\n",
    "should_plot = True\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "conf_matrix = np.zeros((num_classes+1, num_classes+1), dtype=np.int64)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = ThreeLayerSemSegNetWideView(1, 2)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.to(device)\n",
    "\n",
    "model.train(False)\n",
    "\n",
    "num_frames = 0\n",
    "\n",
    "running_loss = 0\n",
    "\n",
    "dataloader = train_dataloader\n",
    "\n",
    "\n",
    "num_batches = 1\n",
    "for batch_ind, batch in enumerate(dataloader):\n",
    "    \n",
    "    \n",
    "    if batch_ind >= num_batches and should_plot:   \n",
    "        break\n",
    "        \n",
    "    im_batch = batch['image'].cuda()\n",
    "#     masks = batch['mask'].cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(im_batch)\n",
    "        num_frames += len(im_batch)\n",
    "#     loss = loss_fn(outputs, masks)\n",
    "#     running_loss += loss.item()*dataloader.batch_size\n",
    "    \n",
    "#     outputs = outputs.cpu().numpy()\n",
    "#     preds = np.argmax(outputs, axis=1)\n",
    "#     masks = batch['mask'].numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     conf_matrix = get_conf_matrix(conf_matrix, num_classes, \n",
    "#                                   preds, masks)\n",
    "    \n",
    "    if should_plot:\n",
    "        for ind in range(len(im_batch)):\n",
    "\n",
    "            if 'orig' in batch.keys():\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(batch['orig'][ind])\n",
    "            plt.figure(figsize=(10,10))\n",
    "            im = im_batch[ind].cpu().numpy()\n",
    "            im = np.transpose(im, (1, 2, 0))\n",
    "            plt.imshow(im)\n",
    "            plt.figure(figsize=(10,10))\n",
    "            im = outputs[ind][0].cpu().numpy()\n",
    "            plt.imshow(im)\n",
    "            plt.title('output')\n",
    "            \n",
    "#             display_im = np.zeros((masks[ind].shape[0], masks[ind].shape[1], 3))\n",
    "#             display_im[..., 0] = masks[ind]\n",
    "# #             display_im[..., 1] = logit2prob(outputs[ind,1])\n",
    "#             display_im[..., 1] = np.argmax(outputs[ind], axis=0)\n",
    "\n",
    "            \n",
    "#             plt.colorbar()\n",
    "#             plt.figure(figsize=(10,10))\n",
    "#             plt.imshow(display_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frame = 100\n",
    "t0 = time.time()\n",
    "for frame_idx, (batch, video_idx, idx) in enumerate(train_dataloader):\n",
    "    if frame_idx != idx:\n",
    "        print(frame_idx, idx)\n",
    "    if frame_idx > max_frame:\n",
    "        break\n",
    "total_time = time.time() - t0\n",
    "print(total_time, total_time / max_frame)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '17Nov'\n",
    "camera_ind = 0\n",
    "\n",
    "kasanka_folder =  '.../kasanka-bats/gopros'\n",
    "\n",
    "camera_folder = sorted(glob.glob(os.path.join(kasanka_folder, date, '*')))[camera_ind]\n",
    "\n",
    "camera_files = sorted(glob.glob(os.path.join(camera_folder, '*.MP4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, _, info = torchvision.io.video.read_video(camera_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, torchvision\n",
    "torch.__version__, torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_url\n",
    "download_url(\"https://github.com/pytorch/vision/blob/master/test/assets/videos/WUzgd7C1pWA.mp4?raw=true\", \".\", \"WUzgd7C1pWA.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"./WUzgd7C1pWA.mp4\"\n",
    "\n",
    "from torchvision.datasets.video_utils import VideoClips\n",
    "video_clips = VideoClips([video_path], clip_length_in_frames=32, frames_between_clips=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips.num_clips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid, _, info, video_idx = video_clips.get_clip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
