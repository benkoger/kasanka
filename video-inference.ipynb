{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torch.utils.data import IterableDataset\n",
    "# from torchvision.datasets.video_utils import VideoClips\n",
    "from video_clip import VideoClips\n",
    "import torch.utils.data as data\n",
    "from bat_seg_models import ThreeLayerSemSegNetWideView, UNET, UNETTraditional\n",
    "from frame_augmentors import MaskNormalize, Mask3dto2d, AddDim, ToFloat, MaskCompose, MaskToTensor\n",
    "import bat_functions\n",
    "from CountLine import CountLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im_file = \".../kasanka-bats/frames/17Nov/card-f/GP039791/GP039791_15948.jpg\"\n",
    "im = plt.imread(im_file)\n",
    "\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_output_folder = '.../kasanka-bats/processed/deep-learning/corrected_model'\n",
    "date = '16Nov'\n",
    "os.makedirs(root_output_folder, exist_ok=True)\n",
    "\n",
    "raw_camera_folders = sorted(glob.glob('.../kasanka-bats/gopros/{}/*'.format(date)))\n",
    "\n",
    "camera_folders = []\n",
    "for camera_folder in raw_camera_folders:\n",
    "    videos = sorted(glob.glob(os.path.join(camera_folder, '*.[Mm][Pp]4')))\n",
    "    camera_name = camera_folder.split('/')[-1]\n",
    "    if not os.path.exists(os.path.join(root_output_folder, date, camera_name, 'centers.npy')):\n",
    "        print(*videos, sep='\\n')\n",
    "        print('--------------')\n",
    "        camera_folders.append(camera_folder)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatIterableDataset(IterableDataset):\n",
    "    def __init__(self, video_files, augmentor=None, max_bad_reads=300):\n",
    "        self.vid_cap = cv2.VideoCapture(video_files[0])\n",
    "        self.video_files = video_files\n",
    "        assert self.vid_cap.isOpened()\n",
    "        self.more_frames = True\n",
    "        # How many times a frame can come up false \n",
    "        # before assuming end of video\n",
    "        self.max_bad_reads = max_bad_reads\n",
    "        self.total_frames_read = 0\n",
    "        self.total_bad_reads = 0\n",
    "        self.augmentor = augmentor\n",
    "        self.video_number = 0\n",
    "        \n",
    "    def more_videos(self):\n",
    "        return self.video_number < len(self.video_files)\n",
    "    \n",
    "    def start_next_video(self):\n",
    "        if self.vid_cap.isOpened():\n",
    "            self.vid_cap.release()\n",
    "        self.video_number += 1\n",
    "        if self.video_number < len(self.video_files):\n",
    "            print('starting new video')\n",
    "            print(self.get_read_frame_info())\n",
    "            self.vid_cap = cv2.VideoCapture(self.video_files[self.video_number])\n",
    "        \n",
    "    def video_generator(self):\n",
    "        while(self.vid_cap.isOpened() or self.more_videos()):\n",
    "            if not self.vid_cap.isOpened():\n",
    "                self.start_next_video()\n",
    "            good_read = False\n",
    "            num_bad_reads = 0\n",
    "            while (not good_read and (num_bad_reads < self.max_bad_reads)):\n",
    "                grabbed, frame = self.vid_cap.read()\n",
    "                if grabbed:\n",
    "                    good_read = True\n",
    "                    self.total_frames_read += 1\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    frame = {'image': frame[2:-2, 2:-2]}\n",
    "                    if np.mean(frame['image'][::50,::50, 2]) < 5:\n",
    "                        print('too dark')\n",
    "                        self.vid_cap.release()\n",
    "                        break\n",
    "                        \n",
    "                    if self.augmentor:\n",
    "                        frame = self.augmentor(frame)\n",
    "                    yield frame\n",
    "                else:\n",
    "                    num_bad_reads += 1\n",
    "                    self.total_bad_reads += 1\n",
    "            if not good_read:\n",
    "                self.vid_cap.release()\n",
    "                print(\"video capture closed\")\n",
    "            \n",
    "    def __iter__(self):\n",
    "        return self.video_generator()\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self.vid_cap.isOpened():\n",
    "            self.vid_cap.release()\n",
    "    \n",
    "    def is_more_frames(self):\n",
    "        return self.vid_cap.isOpened()\n",
    "    \n",
    "    def get_read_frame_info(self):\n",
    "        print('{} frames have been read with {} bad reads'.format(self.total_frames_read,\n",
    "                                                                  self.total_bad_reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './models'\n",
    "\n",
    "# model_filename = 'model_ThreeLayerWide_epochs_10_batcheff_4_lr_0.05_momentum_0.5_aug_aug-no-blur-2d-17Nov-big-dataset.tar'\n",
    "model_filename = 'model_UNET_epochs_100_batcheff_16_lr_0.01_momentum_0.9_aug_aug-2d-20Nov-big-dataset.tar'\n",
    "model_filename = 'model_UNET_epochs_100_batcheff_16_lr_0.01_momentum_0.9_aug_better-norm-aug-2d-20Nov-big-dataset.tar'\n",
    "model_file = os.path.join(folder, model_filename)\n",
    "model_file = './models/model_UNETTraditional_epochs_100_batcheff_16_lr_0.01_momentum_0.9_aug_better-norm-aug-2d-20Nov-big-dataset.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_train_folder = \".../kasanka-bats/annotations\"\n",
    "mean = np.load(os.path.join(root_train_folder, 'mean.npy'))\n",
    "std = np.load(os.path.join(root_train_folder, 'std.npy'))\n",
    "\n",
    "channel = 2\n",
    "       \n",
    "    \n",
    "\n",
    "# augmentor = None\n",
    "bat_datasets = []\n",
    "for camera_folder in camera_folders:\n",
    "    videos = sorted(glob.glob(os.path.join(camera_folder, '*.[Mm][Pp]4')))\n",
    "    augmentor = MaskCompose([Mask3dto2d(channel_to_use=channel),\n",
    "                         MaskToTensor(),\n",
    "                         MaskNormalize(mean[channel]/255, std[channel]/255),\n",
    "                        ])\n",
    "    bat_dataset = BatIterableDataset(videos, augmentor=augmentor)\n",
    "    save_folder = os.path.join(root_output_folder, *camera_folder.split('/')[-2:])\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_folder, 'example-frames'), exist_ok=True)\n",
    "    bat_datasets.append({'dataset':bat_dataset,\n",
    "                         'save_folder': save_folder})\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bat_datasets[0]['dataset']:\n",
    "    break\n",
    "# dataloader = data.DataLoader(bat_dataset['dataset'], \n",
    "#                                  batch_size=batch_size,\n",
    "#                                  shuffle=False, num_workers=0, \n",
    "#                                  pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "# plt.imshow(((np.squeeze(i['image']) - mean) / std)[:,:,1])\n",
    "plt.imshow(np.squeeze(i['image']))\n",
    "plt.colorbar()\n",
    "# plt.figure(figsize=(20,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit2prob(logit):\n",
    "    e_l = np.e ** logit\n",
    "    return e_l \n",
    "\n",
    "def denorm_image(im, mean, std):\n",
    "    \"\"\" Take image the was normalized and return to 0 to 255\"\"\"\n",
    "#     im = np.copy(im)\n",
    "    im *= std\n",
    "    im += mean\n",
    "    im *= 255\n",
    "    im = np.maximum(im, 0)\n",
    "    im = np.minimum(im, 255)\n",
    "    im = im.astype(np.uint8)\n",
    "    \n",
    "    return im\n",
    "\n",
    "should_plot = False\n",
    "should_save = True\n",
    "\n",
    "num_classes = 2\n",
    "bat_prob_thresh = .6\n",
    "batch_size = 2\n",
    "early_stop = None\n",
    "# save some original frames to check detection quality\n",
    "save_every_n_frames = 1350\n",
    "channel = 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = UNETTraditional(1, 2, should_pad=False)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.to(device)\n",
    "\n",
    "model.train(False)\n",
    "\n",
    "for bat_dataset in bat_datasets[:]:\n",
    "\n",
    "    num_frames = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    print(bat_dataset['save_folder'])\n",
    "\n",
    "    dataloader = data.DataLoader(bat_dataset['dataset'], \n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False, num_workers=0, \n",
    "                                 pin_memory=True)\n",
    "\n",
    "    centers_list = []\n",
    "    contours_list = []\n",
    "    sizes_list = []\n",
    "    rects_list = []\n",
    "\n",
    "\n",
    "    for batch_ind, batch in enumerate(dataloader):\n",
    "        if batch_ind == 0:\n",
    "            print('started...')\n",
    "            t0 = time.time()\n",
    "        if early_stop:\n",
    "            if batch_ind >= early_stop:\n",
    "                break\n",
    "\n",
    "        im_batch = batch['image'].cuda()\n",
    "    #     masks = batch['mask'].cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(im_batch)\n",
    "            masks = (outputs[:, 1].cpu().numpy() > np.log(bat_prob_thresh)).astype(np.uint8)\n",
    "            \n",
    "            for ind, mask in enumerate(masks):\n",
    "                centers, areas, contours, _, _, rects = bat_functions.get_blob_info(mask)\n",
    "                centers_list.append(centers)\n",
    "                sizes_list.append(areas)\n",
    "                contours_list.append(contours)\n",
    "                rects_list.append(rects)\n",
    "                if save_every_n_frames:\n",
    "                    if num_frames % save_every_n_frames == 0:\n",
    "                        day = bat_dataset['save_folder'].split('/')[-2]\n",
    "                        card = bat_dataset['save_folder'].split('/')[-1]\n",
    "                        im_name = '{}_{}_obs-ind_{}.jpg'.format(day, card, num_frames)\n",
    "                        im_file = os.path.join(bat_dataset['save_folder'], \n",
    "                                               'example-frames', im_name)\n",
    "                        im = np.squeeze(batch['image'][ind].numpy())\n",
    "                        im = denorm_image(im, mean[channel]/255, std[channel]/255)\n",
    "                        cv2.imwrite(im_file, im)\n",
    "                num_frames += 1\n",
    "\n",
    "\n",
    "        if should_plot:\n",
    "            for ind in range(len(im_batch)):\n",
    "\n",
    "                if 'orig' in batch.keys():\n",
    "                    plt.figure(figsize=(10,10))\n",
    "                    plt.imshow(batch['orig'][ind])\n",
    "                plt.figure(figsize=(10,10))\n",
    "                im = im_batch[ind].cpu().numpy()\n",
    "                im = np.transpose(im, (1, 2, 0))\n",
    "                plt.imshow(im)\n",
    "                plt.figure(figsize=(10,10))\n",
    "                im = outputs[ind][0].cpu().numpy()\n",
    "                plt.imshow(im)\n",
    "                plt.title('output')\n",
    "                prob = logit2prob(outputs[ind,1].cpu().numpy())\n",
    "                mask = (prob > 0.5).astype(np.uint8)\n",
    "\n",
    "    #             display_im = np.zeros_like(im)\n",
    "    #             display_im[..., 0] = masks[ind]\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(mask)\n",
    "    #             plt.colorbar()\n",
    "    #             plt.figure(figsize=(10,10))\n",
    "    #             plt.imshow(display_im)\n",
    "\n",
    "    total_time = time.time() - t0\n",
    "    print(total_time, total_time / batch_ind / batch_size)\n",
    "    print(bat_dataset['dataset'].get_read_frame_info())\n",
    "    if should_save:\n",
    "        save_folder = bat_dataset['save_folder']\n",
    "        num_contour_files = 15\n",
    "        file_num = 0\n",
    "        new_contours = []\n",
    "        for frame_ind, cs in enumerate(contours_list):\n",
    "            if frame_ind % int(len(contours_list)/num_contour_files) == 0:\n",
    "                # start new file\n",
    "                file_name = f'contours-compressed-{file_num:02d}.npy'\n",
    "                file = os.path.join(save_folder, file_name)\n",
    "                np.save(file, np.array(new_contours, dtype=object))\n",
    "                new_contours = []\n",
    "                file_num += 1\n",
    "            new_contours.append([])\n",
    "            for c in cs:\n",
    "                cc\t= np.squeeze(cv2.approxPolyDP(c, 0.1, closed=True))\n",
    "                new_contours[-1].append(cc)\n",
    "        file_name = f'contours-compressed-{file_num:02d}.npy'\n",
    "        file = os.path.join(save_folder, file_name)\n",
    "        np.save(file, np.array(new_contours, dtype=object))\n",
    "        np.save(os.path.join(save_folder, 'size.npy'), sizes_list)\n",
    "        np.save(os.path.join(save_folder,'rects.npy'), rects_list)\n",
    "        np.save(os.path.join(save_folder, 'centers.npy'), centers_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
