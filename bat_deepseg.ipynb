{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bat_seg_models import ThreeLayerSemSegNetWideView, UNET, UNETTraditional\n",
    "from bat_seg_models import ThreeLayerSemSegNetWideViewHighDim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os \n",
    "import cv2\n",
    "\n",
    "    \n",
    "class SegmentationDataset(data.Dataset):\n",
    "    def __init__(self, folder_paths, transform=None, keep_orig=False, max_num_examples=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder_paths (list): list of paths each contains .jpg image files in a folder clled 'images'\n",
    "                and in folder called 'masks' .png masks\n",
    "            transform (callable, optional): Optional transforms to be applied on a sample\n",
    "            keep_orig: keep un-transformed image\n",
    "            max_num_examples: how many examples to used from folder, if None read all\n",
    "        \"\"\"\n",
    "        self.mask_files = []\n",
    "        self.img_files = []\n",
    "        self.keep_orig = keep_orig\n",
    "        self.num_examples = 0\n",
    "            \n",
    "        for folder_path in folder_paths:\n",
    "            possible_img_files = glob.glob(os.path.join(folder_path, 'images', '*.jpg'))\n",
    "            print('{} possible files found'.format(len(possible_img_files)))\n",
    "            if self.num_examples is None:\n",
    "                self.num_examples += len(possible_img_files)\n",
    "            for img_num, img_path in enumerate(possible_img_files):\n",
    "                if not max_num_examples:\n",
    "                    self._add_annotation(folder_path, img_path)\n",
    "                else:\n",
    "                    if self.num_examples < max_num_examples:\n",
    "                        self._add_annotation(folder_path, img_path)\n",
    "                    else:\n",
    "                        break\n",
    "            \n",
    "        self.transform = transform\n",
    "        \n",
    "    def _add_annotation(self, folder_path, img_path):\n",
    "            mask_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            self.mask_files.append(os.path.join(folder_path, 'masks', mask_name + '.png'))\n",
    "            self.img_files.append(img_path)\n",
    "            self.num_examples += 1\n",
    "                                   \n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            mask_path = self.mask_files[index]\n",
    "            image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            sample = {'image': image[2:-2, 2:-2], 'mask': mask[2:-2, 2:-2]}\n",
    "            if self.keep_orig:\n",
    "                sample['orig'] = image\n",
    "            \n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "            return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "class MaskRandomCrop:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, crop_size):\n",
    "        # size of square crop\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        im = sample['image']\n",
    "        mask = sample['mask']\n",
    "\n",
    "        im_height = im.shape[0]\n",
    "        im_width = im.shape[1]\n",
    "        top = np.random.randint(im_height - self.crop_size)\n",
    "        left = np.random.randint(im_width - self.crop_size)\n",
    "\n",
    "        im_crop = im[top:top+self.crop_size, left:left+self.crop_size]\n",
    "        mask_crop = mask[top:top+self.crop_size, left:left+self.crop_size]\n",
    "        \n",
    "        sample['image'] = im_crop\n",
    "        sample['mask'] = mask_crop\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class MaskImgAug:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # size of square crop\n",
    "        self.transform = iaa.Sequential([\n",
    "#             iaa.AdditiveGaussianNoise(scale=(0, 0.1*255)),\n",
    "            iaa.Sometimes(0.4, iaa.blur.GaussianBlur(sigma=(0.0, 6.0))),\n",
    "            iaa.Sometimes(0.4, iaa.AdditivePoissonNoise((0, 30)))\n",
    "        ])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        im = sample['image'].astype(np.uint8)\n",
    "        im_transform = self.transform(image=np.array(im))\n",
    "        sample['image'] = im_transform.astype(float)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "class Mask2dMultiplyAndAddToBrightness():\n",
    "    def __init__(self, add, multiply):\n",
    "        \"\"\"Add and multiply image values by given amount randomly within range.\n",
    "        \n",
    "        Expects image to be between 0 and 255.\n",
    "        \n",
    "        Args:\n",
    "            add: either number of tuple, if tuple randomly choose from range\n",
    "            multiply: either number ot tuple, if tuple randomly choose from range\n",
    "        \"\"\"\n",
    "        self.add = add\n",
    "        self.multiply = multiply\n",
    "        self.rng = np.random.default_rng()\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        im = sample['image'].astype(np.float64)\n",
    "        if isinstance(self.add, tuple):\n",
    "            add_val = self.rng.uniform(self.add[0], self.add[1])\n",
    "        else:\n",
    "            add_val = self.add\n",
    "        if isinstance(self.multiply, tuple):\n",
    "            multiply_val = self.rng.uniform(self.multiply[0], self.multiply[1])\n",
    "        else:\n",
    "            multiply_val = self.multiply\n",
    "        im += add_val\n",
    "        im *= multiply_val\n",
    "        im = np.maximum(im, 0)\n",
    "        im = np.minimum(im, 255)\n",
    "        \n",
    "        sample['image'] = im\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "class MaskToTensor:\n",
    "    def __call__(self, sample):\n",
    "        im = sample['image']\n",
    "        mask = sample['mask']\n",
    "        \n",
    "        im_tensor = torch.from_numpy(im).float() / 255\n",
    "        im_tensor = torch.unsqueeze(im_tensor, 0)\n",
    "        mask_tensor = torch.from_numpy(np.array(mask, np.int64, copy=False))\n",
    "        mask_tensor = mask_tensor // 255\n",
    "        \n",
    "        sample['image'] = im_tensor\n",
    "        sample['mask'] = mask_tensor\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "class Mask3dto2d:\n",
    "    \"\"\" Expects images of size NxMxC\"\"\"\n",
    "    def __init__(self, channel_to_use):\n",
    "        self.channel_to_use = channel_to_use\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        im = sample['image']\n",
    "        sample['image'] = im[..., self.channel_to_use]\n",
    "       \n",
    "        return sample\n",
    "    \n",
    "class MaskCompose:\n",
    "    def __init__(self, transform_list):\n",
    "        \"\"\"Chain together transforms in transform.\n",
    "         Expect transform on both image and mask in dict\n",
    "         \n",
    "         Args:\n",
    "             transform_list (list): list of custom augmentations\n",
    "         \"\"\"\n",
    "        self.transform_list = transform_list\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        for transform in self.transform_list:\n",
    "            sample  = transform(sample)\n",
    "        return sample\n",
    "    \n",
    "class MaskNormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        \"\"\"Normalize image, leave mask unchanged\"\"\"\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        im = sample['image']\n",
    "        im_norm = TF.normalize(im, self.mean, self.std)\n",
    "        \n",
    "        sample['image'] = im_norm\n",
    "        return sample\n",
    "    \n",
    "class MaskContrast:\n",
    "    def __init__(self, contrast_factor):\n",
    "        \"\"\"Change image contrast, leave mask unchanged\n",
    "        \n",
    "        Args:\n",
    "            contrast_factor: single value or tuple\"\"\"\n",
    "        self.contrast_factor = contrast_factor\n",
    "        self.rng = np.random.default_rng()\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        im = sample['image']\n",
    "        if isinstance(self.contrast_factor, tuple):\n",
    "            contrast_factor = self.rng.uniform(self.contrast_factor[0], self.contrast_factor[1])\n",
    "        else:\n",
    "            contrast_factor = self.contrast_factor\n",
    "        im_height, im_width = im.shape\n",
    "        aprox_mean = np.mean([im[0,0], im[-1, 0], im[0, -1], im[-1, -1], \n",
    "                              im[im_height//2, im_width//2], im[-im_height//2, -im_width//2]])\n",
    "        im_contrast = aprox_mean + contrast_factor * (im - aprox_mean)\n",
    "        im_contrast = np.maximum(im_contrast, 0)\n",
    "        im_contrast = np.minimum(im_contrast, 255)\n",
    "        sample['image'] = im_contrast\n",
    "        return sample\n",
    "    \n",
    "class MaskCenterImage:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, sample):\n",
    "        im = sample['image']\n",
    "        mean = np.mean(im[::10, ::10])\n",
    "        bias = 125 - int(mean)\n",
    "        bias = np.max([0, bias])\n",
    "        sample['image'] += bias\n",
    "        sample['image'] = np.where(sample['image'] > 255, 255, sample['image'])\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "root_train_folder = \".../kasanka-bats/annotations\"\n",
    "root_test_folder = \".../bats-code/data/test\"\n",
    "root_val_folder = \".../kasanka-bats/annotations/val_set\"\n",
    "mean = np.load(os.path.join(root_train_folder, 'mean.npy'))\n",
    "std = np.load(os.path.join(root_train_folder, 'std.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_matrix(conf_matrix, num_classes, pred_batch, mask_batch):\n",
    "    \"\"\" Calculate confusion matrix and add to passed confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        conf_matrix (np array): confusion matrix size \n",
    "            (num_classes + 1, num_classes + 1)\n",
    "        num_classes (int): number of classes being segmented\n",
    "        pred_batch (np array): NxM or BxNxM\n",
    "        mask_batch (np array): NxM or BxNxM\n",
    "    \"\"\"\n",
    "    \n",
    "    N = num_classes + 1\n",
    "\n",
    "    if len(pred_batch.shape) == 2:\n",
    "        pred_batch = np.expand_dims(pred_batch, 0)\n",
    "        mask_batch = np.expand_dims(mask_batch, 0)\n",
    "    for pred, mask in zip(pred_batch, mask_batch):\n",
    "        conf_matrix += np.bincount(\n",
    "            N * pred.reshape(-1) + mask.reshape(-1), minlength=N ** 2\n",
    "        ).reshape(N, N)\n",
    "    return conf_matrix\n",
    "\n",
    "def evaluate(num_classes, conf_matrix):\n",
    "    \"\"\" Caclculate Accuracy and IOU scores.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): num classes\n",
    "        conf_matrix (np array): confusion matrix of size \n",
    "            (num_classes + 1, num_classes + 1)\n",
    "    \"\"\"\n",
    "    acc = np.full(num_classes, np.nan, dtype=np.float)\n",
    "    iou = np.full(num_classes, np.nan, dtype=np.float)\n",
    "    tp = conf_matrix.diagonal()[:-1].astype(np.float)\n",
    "    pos_gt = np.sum(conf_matrix[:-1, :-1], axis=0).astype(np.float)\n",
    "    class_weights = pos_gt / np.sum(pos_gt)\n",
    "    pos_pred = np.sum(conf_matrix[:-1, :-1], axis=1).astype(np.float)\n",
    "    acc_valid = pos_gt > 0\n",
    "    acc[acc_valid] = tp[acc_valid] / pos_gt[acc_valid]\n",
    "    iou_valid = (pos_gt + pos_pred) > 0\n",
    "    union = pos_gt + pos_pred - tp\n",
    "    iou[acc_valid] = tp[acc_valid] / union[acc_valid]\n",
    "    macc = np.sum(acc[acc_valid]) / np.sum(acc_valid)\n",
    "    miou = np.sum(iou[acc_valid]) / np.sum(iou_valid)\n",
    "    fiou = np.sum(iou[acc_valid] * class_weights[acc_valid])\n",
    "    pacc = np.sum(tp) / np.sum(pos_gt)\n",
    "    \n",
    "    return iou, acc\n",
    "\n",
    "import time\n",
    "# def train(model, num_classes, train_dl, val_dl, loss_fn, optimizer, model_file,\n",
    "#           acc_fn, epochs=1, accumulation_steps=1, val_epoch=1, show_images=False):\n",
    "#     start = time.time()\n",
    "    \n",
    "#     train_loss, valid_loss = [], []\n",
    "    \n",
    "#     # calc max usuable batchnum\n",
    "#     max_batchnum = ((len(train_dl) // accumulation_steps) \n",
    "#                     * accumulation_steps)\n",
    "#     print(\"using {} batches ({} images)\".format(\n",
    "#         max_batchnum, max_batchnum * train_dl.batch_size))\n",
    "    \n",
    "#     model.cuda()\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "        \n",
    "#         if epoch % 1 == 0:\n",
    "#             print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "#         if epoch % 10 == 0:\n",
    "#             torch.save(model.state_dict(), '{}_epoch_{}.tar'.format(model_file, epoch))\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         for phase in ['train', 'val']:\n",
    "#             phase_start = time.time()\n",
    "#             if phase == 'train':\n",
    "#                 model.train(True)\n",
    "#                 dataloader = train_dl\n",
    "#             else:\n",
    "#                 if epoch % val_epoch != 0:\n",
    "#                     continue\n",
    "#                 model.train(False)\n",
    "#                 dataloader = val_dl\n",
    "#                 conf_matrix = np.zeros((num_classes+1, num_classes+1), dtype=np.int64)\n",
    "                \n",
    "#             running_loss = 0.0\n",
    "#             running_acc = 0.0\n",
    "            \n",
    "#             step = 0\n",
    "            \n",
    "            \n",
    "            \n",
    "#             # iterate over data\n",
    "#             for batch_ind, batch in enumerate(dataloader):\n",
    "#                 if batch_ind >= max_batchnum:\n",
    "#                     break\n",
    "#                 im_batch = batch['image'].cuda()\n",
    "#                 masks = batch['mask'].cuda()\n",
    "                \n",
    "#                 if phase == 'train':\n",
    "#                     outputs = model(im_batch)\n",
    "#                     loss = loss_fn(outputs, masks)\n",
    "#                     loss.backward()\n",
    "#                     if (batch_ind+1) % accumulation_steps == 0:\n",
    "#                         # Wait for several backward steps\n",
    "#                         # Now we can do an optimizer step\n",
    "#                         optimizer.step()                            \n",
    "#                         model.zero_grad() \n",
    "#                 else:\n",
    "#                     with torch.no_grad():\n",
    "#                         outputs = model(im_batch)\n",
    "#                         loss = loss_fn(outputs, masks)\n",
    "#                         np_outputs = outputs.cpu().numpy()\n",
    "#                         np_preds = np.argmax(np_outputs, axis=1)\n",
    "#                         np_masks = masks.cpu().numpy()\n",
    "#                         conf_matrix = get_conf_matrix(conf_matrix, num_classes, \n",
    "#                                                       np_preds, np_masks)\n",
    "                        \n",
    "#                 if show_images:\n",
    "#                     np_im_batch = batch['image'].numpy()\n",
    "#                     for im in np_im_batch:\n",
    "#                         plt.figure()\n",
    "#                         plt.imshow(np.squeeze(im))\n",
    "#                         plt.title(phase)\n",
    "\n",
    "#                 running_loss += loss.item()*dataloader.batch_size\n",
    "                \n",
    "                \n",
    "#                 step += 1\n",
    "                \n",
    "#             epoch_loss = running_loss / len(dataloader.dataset)\n",
    "#             if epoch % 1 == 0:\n",
    "                \n",
    "#                 phase_length = time.time() - phase_start\n",
    "#                 fps =  (len(dataloader) * len(batch)) / phase_length\n",
    "                \n",
    "#                 print('{} Loss: {:.4f}  AllocMem (Mb): {:.3f} MaxMem(Mb) {:.3f}Time: {:.3f} fps: {:.3f}'.format(\n",
    "#                     phase, epoch_loss, torch.cuda.memory_allocated()/1024/1024, \n",
    "#                     torch.cuda.max_memory_allocated()/1024/1024, phase_length, fps))\n",
    "#             if phase == 'val':\n",
    "#                 iou, acc = evaluate(num_classes, conf_matrix)\n",
    "#                 print('IOU: {}, Acc: {}'.format(iou, acc))\n",
    "#             train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
    "\n",
    "#         time_elapsed = time.time() - start   \n",
    "\n",
    "#     return train_loss, valid_loss \n",
    "    \n",
    "def acc_metric(predb, yb):\n",
    "    return (predb.argmax(dim=1) == yb.cuda()).float().mean()\n",
    "\n",
    "def train(model, num_classes, train_dl, val_dl, loss_fn, optimizer, \n",
    "          acc_fn, epochs=1, lr_scheduler=None, save_best_val=False,\n",
    "          model_file='model.tar', accumulation_steps=1, val_epoch=1, \n",
    "          show_images=False):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss, valid_loss = [], []\n",
    "    \n",
    "    # calc max usuable batchnum\n",
    "    max_batchnum = ((len(train_dl) // accumulation_steps) \n",
    "                    * accumulation_steps)\n",
    "    print(\"using {} batches ({} images)\".format(\n",
    "        max_batchnum, max_batchnum * train_dl.batch_size))\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    top_val_loss = 100000000000\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            phase_start = time.time()\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "                dataloader = train_dl\n",
    "            else:\n",
    "                if epoch % val_epoch != 0:\n",
    "                    continue\n",
    "                model.train(False)\n",
    "                dataloader = val_dl\n",
    "                conf_matrix = np.zeros((num_classes+1, num_classes+1), dtype=np.int64)\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            \n",
    "            step = 0\n",
    "            \n",
    "            \n",
    "            \n",
    "            # iterate over data\n",
    "            for batch_ind, batch in enumerate(dataloader):\n",
    "                if batch_ind >= max_batchnum:\n",
    "                    break\n",
    "                im_batch = batch['image'].cuda()\n",
    "                masks = batch['mask'][:, 24:-24, 24:-24].cuda()\n",
    "#                 print(batch['image'].size(), batch['mask'][46:-46, 46:-46].shape)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    outputs = model(im_batch)\n",
    "                    loss = loss_fn(outputs, masks)\n",
    "                    loss.backward()\n",
    "                    if (batch_ind+1) % accumulation_steps == 0:\n",
    "                        # Wait for several backward steps\n",
    "                        # Now we can do an optimizer step\n",
    "                        optimizer.step()\n",
    "                        if lr_scheduler:\n",
    "                            lr_scheduler.step()\n",
    "                        model.zero_grad() \n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(im_batch)\n",
    "                        loss = loss_fn(outputs, masks)\n",
    "                        np_outputs = outputs.cpu().numpy()\n",
    "                        np_preds = np.argmax(np_outputs, axis=1)\n",
    "                        np_masks = masks.cpu().numpy()\n",
    "                        conf_matrix = get_conf_matrix(conf_matrix, num_classes, \n",
    "                                                      np_preds, np_masks)\n",
    "                        \n",
    "                if show_images:\n",
    "                    np_im_batch = batch['image'].numpy()\n",
    "                    for im in np_im_batch:\n",
    "                        plt.figure()\n",
    "                        plt.imshow(np.squeeze(im))\n",
    "                        plt.title(phase)\n",
    "\n",
    "                running_loss += loss.item()*dataloader.batch_size\n",
    "                \n",
    "                \n",
    "                step += 1\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            if epoch % 1 == 0:\n",
    "                \n",
    "                phase_length = time.time() - phase_start\n",
    "                fps =  (len(dataloader) * len(batch)) / phase_length\n",
    "                \n",
    "                print('{} Loss: {:.4f}  AllocMem (Mb): {:.3f} MaxMem(Mb) {:.3f}Time: {:.3f} fps: {:.3f}'.format(\n",
    "                    phase, epoch_loss, torch.cuda.memory_allocated()/1024/1024, \n",
    "                    torch.cuda.max_memory_allocated()/1024/1024, phase_length, fps))\n",
    "            if phase == 'val':\n",
    "                valid_loss.append(epoch_loss)\n",
    "                if epoch_loss < top_val_loss:\n",
    "                    top_val_loss = epoch_loss\n",
    "                    if save_best_val:\n",
    "                        torch.save(model.state_dict(), model_file)\n",
    "                        print('saved new model. val loss {}'.format(epoch_loss))\n",
    "                    \n",
    "                iou, acc = evaluate(num_classes, conf_matrix)\n",
    "                print('IOU: {}, Acc: {}'.format(iou, acc))\n",
    "            else:\n",
    "                train_loss.append(epoch_loss) \n",
    "\n",
    "        time_elapsed = time.time() - start   \n",
    "\n",
    "    return train_loss, valid_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 2\n",
    "\n",
    "im_size = 1024 #532\n",
    "\n",
    "none_data_transforms = torchvision.transforms.Compose([\n",
    "                                                        Mask3dto2d(channel),\n",
    "                                                        MaskRandomCrop(im_size),\n",
    "                                                        MaskToTensor(), \n",
    "                                                        MaskNormalize(mean[channel]/255, std[channel]/255)])\n",
    "\n",
    "easy_data_transforms = torchvision.transforms.Compose([\n",
    "                                                        Mask3dto2d(channel),\n",
    "                                                        MaskRandomCrop(im_size),\n",
    "                                                        Mask2dMultiplyAndAddToBrightness(\n",
    "                                                                multiply=(0.5, 1.2), add=(-50, 0)),\n",
    "                                                        MaskContrast(contrast_factor=(0.6, 1.3)),\n",
    "                                                        MaskImgAug(),\n",
    "                                                        MaskToTensor(), \n",
    "                                                        MaskNormalize(mean[channel]/255, std[channel]/255)])\n",
    "\n",
    "hard_data_transforms = torchvision.transforms.Compose([\n",
    "                                                        Mask3dto2d(channel),\n",
    "                                                        MaskRandomCrop(im_size),\n",
    "                                                        Mask2dMultiplyAndAddToBrightness(\n",
    "                                                                multiply=(0.1, 1.2), add=(-50, 0)),\n",
    "                                                        MaskContrast(contrast_factor=(0.3, 1.3)),\n",
    "                                                        MaskImgAug(),\n",
    "                                                        MaskToTensor(), \n",
    "                                                        MaskNormalize(mean[channel]/255, std[channel]/255)])\n",
    "\n",
    "# train_data_transforms = torchvision.transforms.Compose([\n",
    "#                                                         Mask3dto2d(channel),\n",
    "#                                                         MaskRandomCrop(1024),\n",
    "#                                                         MaskToTensor(), \n",
    "#                                                         MaskNormalize(mean[channel], std[channel])])\n",
    "\n",
    "\n",
    "visualize_data_transforms = torchvision.transforms.Compose([\n",
    "                                                            Mask3dto2d(channel),\n",
    "                                                            MaskRandomCrop(im_size),\n",
    "                                                            MaskToTensor(),\n",
    "                                                            MaskNormalize(mean[channel]/255, std[channel]/255)\n",
    "                                                           ])\n",
    "\n",
    "\n",
    "\n",
    "val_data_transforms = torchvision.transforms.Compose([\n",
    "                                                      Mask3dto2d(channel),\n",
    "                                                      MaskRandomCrop(im_size), \n",
    "                                                      MaskToTensor(), \n",
    "                                                      MaskNormalize(mean[channel]/255, std[channel]/255)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "\n",
    "    np.random.seed(datetime.datetime.now().microsecond + worker_id * 1000000)\n",
    "#     ia.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "\n",
    "batch_size = 4 #was 4\n",
    "\n",
    "train_dataset_no_aug = SegmentationDataset(\n",
    "    [root_train_folder], none_data_transforms, max_num_examples=None)\n",
    "train_dataloader_no_aug = data.DataLoader(train_dataset_no_aug, batch_size=batch_size,\n",
    "                                   shuffle=True, num_workers=7, pin_memory=True,\n",
    "                                   worker_init_fn=worker_init_fn)\n",
    "\n",
    "train_dataset_easy_aug = SegmentationDataset(\n",
    "    [root_train_folder], easy_data_transforms, max_num_examples=None)\n",
    "train_dataloader_easy_aug = data.DataLoader(train_dataset_easy_aug, batch_size=batch_size,\n",
    "                                   shuffle=True, num_workers=7, pin_memory=True,\n",
    "                                   worker_init_fn=worker_init_fn)\n",
    "\n",
    "train_dataset_hard_aug = SegmentationDataset(\n",
    "    [root_train_folder], hard_data_transforms, max_num_examples=None)\n",
    "train_dataloader_hard_aug = data.DataLoader(train_dataset_hard_aug, batch_size=batch_size,\n",
    "                                   shuffle=True, num_workers=7, pin_memory=True,\n",
    "                                   worker_init_fn=worker_init_fn)\n",
    "visualize_dataset = SegmentationDataset([root_train_folder], visualize_data_transforms)\n",
    "\n",
    "val_dataset = SegmentationDataset(\n",
    "    [root_val_folder], hard_data_transforms, max_num_examples=None)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                 shuffle=False, num_workers=7, pin_memory=True,\n",
    "                                 worker_init_fn=worker_init_fn)\n",
    "\n",
    "raw_dataset = SegmentationDataset([root_train_folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('image', train_dataset_no_aug[0]['image'].shape)\n",
    "print('mask', train_dataset_no_aug[0]['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset_no_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in np.linspace(0, len(visualize_dataset), 5, dtype=int, endpoint=False):\n",
    "# for ind in np.random.choice(len(visualize_dataset), 5):\n",
    "for ind in range(4):\n",
    "    \n",
    "    sample = train_dataset_hard_aug[ind]\n",
    "    im = sample['image'].numpy()\n",
    "    mask = sample['mask'].numpy()\n",
    "    im = np.squeeze(im)\n",
    "    if len(im.shape) == 3:\n",
    "        im = np.transpose(im, (1, 2, 0))\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.imshow(im, vmin=0, vmax=1.0)\n",
    "#     plt.colorbar()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(im)\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleCNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.name = 'DoubleCNNBlock'\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                            stride=1, padding=padding),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, \n",
    "                            stride=1, padding=padding),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class ContractBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.name = \"ContractBlock\"\n",
    "        \n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            DoubleCNNBlock(in_channels, out_channels, kernel_size, padding)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "    \n",
    "class ExpandBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.name = \"ExpandBlock\"\n",
    "        \n",
    "        self.expand = torch.nn.ConvTranspose2d(in_channels, in_channels//2, \n",
    "                                               kernel_size=3, stride=2, \n",
    "                                               padding=1, output_padding=1\n",
    "                                              )\n",
    "        self.conv = DoubleCNNBlock(in_channels, out_channels, kernel_size, padding)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1_expand = self.expand(x1)\n",
    "        # Assumes dims have been corrected/padded to match elsewhere\n",
    "        x = torch.cat([x1_expand, x2], dim=1)\n",
    "        return self.conv(x)\n",
    "    \n",
    "    \n",
    "class UNETShortened(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, should_pad=True):\n",
    "        super().__init__()\n",
    "        self.name = 'UNETTraditional'\n",
    "        if should_pad:\n",
    "            conv1_pad = 3\n",
    "            gen_pad = 1\n",
    "        else:\n",
    "            conv1_pad = 0\n",
    "            gen_pad = 0\n",
    "        self.conv1 = DoubleCNNBlock(in_channels, 32, 7, conv1_pad)\n",
    "        self.conv2 = ContractBlock(32, 64, 3, gen_pad)\n",
    "        self.conv3 = ContractBlock(64, 128, 3, gen_pad)\n",
    "\n",
    "        self.upconv1 = ExpandBlock(128, 64, 3, gen_pad)\n",
    "        self.upconv2 = ExpandBlock(64, 32, 3, gen_pad)\n",
    "        \n",
    "        self.outconv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # downsampling part\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        \n",
    "        conv2_crop = 4\n",
    "        cropped_conv2 = conv2[:, :, conv2_crop:-conv2_crop, conv2_crop:-conv2_crop]\n",
    "        upconv1 = self.upconv1(conv3, cropped_conv2)\n",
    "        conv1_crop = 16\n",
    "        cropped_conv1 = conv1[:, :, conv1_crop:-conv1_crop, conv1_crop:-conv1_crop]\n",
    "        upconv2 = self.upconv2(upconv1, cropped_conv1)\n",
    "        \n",
    "        outconv = self.outconv(upconv2)\n",
    "        xout = self.softmax(outconv)\n",
    "\n",
    "        return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SimpleSemSegNet(3, 2)\n",
    "# model = SuperSimpleSemSegNet(3, 2)\n",
    "# model = ThreeLayerSemSegNet(1, 2)\n",
    "# model = ThreeLayerSemSegNetWideViewHighDim(1, 2)\n",
    "# model = FourLayerSemSegNetWideView(1, 2)\n",
    "# model = UNET(1, 2, should_pad=False)\n",
    "model = UNETTraditional(1, 2, should_pad=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01\n",
    "accumulation_steps = 4\n",
    "epochs = 100 #0\n",
    "momentum = 0.9\n",
    "model_name = \"UNETTraditional\"\n",
    "aug_type = \"better-norm-aug-2d-20Nov-big-dataset\"\n",
    "\n",
    "folder = './models'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "model_name = 'model_{}_epochs_{}_batcheff_{}_lr_{}_momentum_{}_aug_{}'.format(\n",
    "    model_name, epochs, accumulation_steps*batch_size, lr, momentum, aug_type)\n",
    "\n",
    "model_file = os.path.join(folder, model_name + '.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    \"\"\" To pass to torch optim lr_scheduler.\n",
    "    \n",
    "    Args:\n",
    "        epoch: current epoch number\n",
    "        \n",
    "    return number to multiply base lr\n",
    "    \"\"\"\n",
    "    \n",
    "    if epoch < 15:\n",
    "        return 1.0\n",
    "    elif epoch < 30:\n",
    "        return 0.2\n",
    "    else:\n",
    "        return 0.05\n",
    "\n",
    "\n",
    "optimizer_none = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler_none = torch.optim.lr_scheduler.LambdaLR(optimizer_none, lr_scheduler, last_epoch=-1)\n",
    "\n",
    "optimizer_easy = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler_easy = torch.optim.lr_scheduler.LambdaLR(optimizer_easy, lr_scheduler, last_epoch=-1)\n",
    "\n",
    "optimizer_hard = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler_hard = torch.optim.lr_scheduler.LambdaLR(optimizer_hard, lr_scheduler, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_loss = []\n",
    "total_val_loss = []\n",
    "\n",
    "no_aug_epochs = 1\n",
    "easy_epochs = 30\n",
    "hard_epochs = 60\n",
    "\n",
    "\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.NLLLoss(weight=torch.tensor([.01, .99]).cuda())\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "train_loss, val_loss = train(model, 2, train_dataloader_no_aug, val_dataloader,\n",
    "                            loss_fn, optimizer_none, acc_metric, epochs=no_aug_epochs, \n",
    "                             accumulation_steps=accumulation_steps, val_epoch=1,\n",
    "                             lr_scheduler=scheduler_none, save_best_val=True,\n",
    "                             model_file=model_file, show_images=False)\n",
    "total_train_loss.extend(train_loss)\n",
    "total_val_loss.extend(val_loss)\n",
    "\n",
    "train_loss, val_loss = train(model, 2, train_dataloader_easy_aug, val_dataloader,\n",
    "                            loss_fn, optimizer_easy, acc_metric, epochs=easy_epochs, \n",
    "                             accumulation_steps=accumulation_steps, val_epoch=2,\n",
    "                             lr_scheduler=scheduler_easy, save_best_val=True,\n",
    "                             model_file=model_file, show_images=False)\n",
    "total_train_loss.extend(train_loss)\n",
    "total_val_loss.extend(val_loss)\n",
    "\n",
    "train_loss, val_loss = train(model, 2, train_dataloader_hard_aug, val_dataloader,\n",
    "                            loss_fn, optimizer_hard, acc_metric, epochs=hard_epochs, \n",
    "                             accumulation_steps=accumulation_steps, val_epoch=2,\n",
    "                             lr_scheduler=scheduler_hard, save_best_val=True,\n",
    "                             model_file=model_file, show_images=False)\n",
    "total_train_loss.extend(train_loss)\n",
    "total_val_loss.extend(val_loss)\n",
    "\n",
    "plt.plot(train_loss[:])\n",
    "plt.plot(val_loss[:])\n",
    "\n",
    "save_model = True\n",
    "\n",
    "if save_model:\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss[:])\n",
    "plt.plot(val_loss[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train_loss = np.copy(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss[:])\n",
    "plt.plot(val_loss[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'model_ThreeLayerWide_epochs_10_batcheff_4_lr_0.05_momentum_0.5_aug_aug-no-blur-2d-17Nov-big-dataset.tar'\n",
    "model_file = os.path.join(folder, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_data_transforms = torchvision.transforms.Compose([\n",
    "                                                        Mask3dto2d(channel),\n",
    "#                                                         MaskRandomCrop(532),\n",
    "                                                        MaskToTensor(), \n",
    "                                                        MaskNormalize(mean[channel]/255, std[channel]/255)\n",
    "                                                        ]\n",
    "                                                     )\n",
    "test_dataset = SegmentationDataset([root_test_folder], test_data_transforms, keep_orig=True)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=7, pin_memory=True, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_dataloader:\n",
    "    break\n",
    "print(i['image'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 0\n",
    "for x in test_dataloader:\n",
    "    y = x\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in model.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in model.buffers()])\n",
    "mem = mem_params + mem_bufs # in bytes\n",
    "print(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.NLLLoss(weight=torch.tensor([.08, .92]).cuda())\n",
    "should_plot = True\n",
    "def acc_metric_cpu(predb, yb):\n",
    "    return (np.mean(np.argmax(predb, axis=1) == yb).astype(float))\n",
    "\n",
    "def logit2prob(logit):\n",
    "    e_l = np.e ** logit\n",
    "    return e_l \n",
    "\n",
    "def rescale(im):\n",
    "    im -= im.min()\n",
    "    im /= im.max()\n",
    "    im *= 255\n",
    "    return im.astype(int)\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "conf_matrix = np.zeros((num_classes+1, num_classes+1), dtype=np.int64)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = UNETTraditional(1, 2, should_pad=False)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.to(device)\n",
    "\n",
    "model.train(False)\n",
    "\n",
    "num_frames = 0\n",
    "\n",
    "running_loss = 0\n",
    "\n",
    "dataloader = test_dataloader #train_dataset_no_aug\n",
    "\n",
    "\n",
    "num_batches = 10\n",
    "padded_edge = 24\n",
    "\n",
    "for batch_ind, batch in enumerate(dataloader):\n",
    "    \n",
    "    \n",
    "    if batch_ind >= num_batches and should_plot:   \n",
    "        break\n",
    "        \n",
    "    im_batch = batch['image'].cuda()\n",
    "    masks = batch['mask'][:, padded_edge:-padded_edge, padded_edge:-padded_edge].cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(im_batch)\n",
    "        num_frames += len(im_batch)\n",
    "    loss = loss_fn(outputs, masks)\n",
    "    running_loss += loss.item()*dataloader.batch_size\n",
    "    \n",
    "    outputs = outputs.cpu().numpy()\n",
    "    preds = np.argmax(outputs, axis=1)\n",
    "    masks = batch['mask'][:, padded_edge:-padded_edge, padded_edge:-padded_edge].numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    conf_matrix = get_conf_matrix(conf_matrix, num_classes, \n",
    "                                  preds, masks)\n",
    "    \n",
    "    if should_plot:\n",
    "        for ind in range(len(im_batch)):\n",
    "\n",
    "            if 'orig' in batch.keys():\n",
    "                plt.figure(figsize=(20,20))\n",
    "                plt.imshow(batch['orig'][ind])\n",
    "            plt.figure(figsize=(20,20))\n",
    "            im = im_batch[ind].cpu().numpy()\n",
    "            im = np.transpose(im, (1, 2, 0))\n",
    "            plt.imshow(rescale(im)[padded_edge:-padded_edge, padded_edge:-padded_edge])\n",
    "            \n",
    "            display_im = np.zeros((masks[ind].shape[0], masks[ind].shape[1], 3))\n",
    "            display_im[..., 0] = masks[ind]\n",
    "#             display_im[..., 1] = logit2prob(outputs[ind,1])\n",
    "            prob_bat = logit2prob(outputs[ind,1])\n",
    "#             display_im[..., 1] = logit2prob(outputs[ind,1])\n",
    "            display_im[..., 1] = np.where(prob_bat>.8, 1, 0)\n",
    "#             display_im[..., 1] = np.argmax(outputs[ind], axis=0)\n",
    "\n",
    "            \n",
    "#             plt.colorbar()\n",
    "            plt.figure(figsize=(20,20))\n",
    "            plt.imshow(display_im)\n",
    "                                        \n",
    "                                            \n",
    "#             plt.imshow(masks[ind])\n",
    "#             plt.figure(figsize=(10,10))\n",
    "#             plt.imshow(logit2prob(outputs[ind,1]))\n",
    "#             plt.colorbar()\n",
    "    \n",
    "        \n",
    "    \n",
    "print('num_images:', num_frames)    \n",
    "    \n",
    "print(evaluate(num_classes, conf_matrix))\n",
    "print('epoch loss {}'.format(running_loss / len(dataloader.dataset)))\n",
    "\n",
    "\n",
    "\n",
    "# print(acc_metric_cpu(outputs, masks))\n",
    "\n",
    "\n",
    "print('(array([0.89453741, 0.01963136]), array([0.89547724, 0.66801191]))')\n",
    "print('(array([0.85383388, 0.00903547]), array([0.85550988, 0.40486206]))')\n",
    "print('(array([0.99741196, 0.35509281]), array([0.99923319, 0.43878196]))')\n",
    "print('(array([0.99821493, 0.49235221]), array([0.99971842, 0.53513952]))')\n",
    "print('(array([0.99855523, 0.58660997]), array([0.99952043, 0.679801  ]))')\n",
    "print('(array([0.99460785, 0.24880005]), array([0.99551585, 0.66193785]))')\n",
    "print('(array([0.99841432, 0.50716247]), array([0.99947347, 0.60627301]))')\n",
    "print('(array([0.97783943, 0.06026228]), array([0.97892977, 0.56061034]))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "plt.figure(figsize=(5,5))\n",
    "im = im_batch[ind].cpu().numpy()\n",
    "im = np.transpose(im, (1, 2, 0))\n",
    "plt.imshow(rescale(im[:1000, :1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = []\n",
    "for i in range(10):\n",
    "    total = 0\n",
    "    bat = 0\n",
    "    for batch_ind, batch in enumerate(train_dataloader):\n",
    "        mask = batch['mask'].numpy() \n",
    "        total += mask.shape[0] * mask.shape[1] * mask.shape[2]\n",
    "        bat += np.sum(mask)\n",
    "    background.append((total - bat) / total)\n",
    "print(np.mean(np.array(background)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in preds:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_out = output.detach().numpy()\n",
    "plt.imshow(np_out[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data_loader[0]\n",
    "im = sample['image']\n",
    "mask = sample['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.squeeze(np.transpose(mask.numpy(), (1, 2, 0)))\n",
    "im = np.transpose(im.numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = torch.rand((1, 1, 28, 28))\n",
    "\n",
    "my_nn = Net()\n",
    "result = my_nn(random_data)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(result, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nn.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(my_nn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
