{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take the frame based detections and turn them into movement trajectories\n",
    "(For speed, uses multiprocessing and breaks up observations into 10 overlapping temporal groups to process seperately since tracks are much shorter in time than the total length of the obervations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "import bat_functions as kbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \".../kasanka-bats/processed/deep-learning\"\n",
    "# Which day to track\n",
    "day = \"16Nov\"\n",
    "camera_folders = sorted(glob.glob(os.path.join(base_folder, day, '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_camera_folders = []\n",
    "for folder in camera_folders:\n",
    "    tracks_file = os.path.join(folder, \"raw_tracks.npy\")\n",
    "    if os.path.exists(tracks_file):\n",
    "        # Skip videos that have already been tracked\n",
    "        continue\n",
    "    else:\n",
    "        n_camera_folders.append(folder)\n",
    "\n",
    "print(\"Videos to track...\")\n",
    "print(*n_camera_folders, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(camera_dict):\n",
    "    camera_folder = camera_dict['camera_folder']\n",
    "    first_frame = camera_dict['first_frame']\n",
    "    max_frame = camera_dict['max_frame']\n",
    "    print(f\"{os.path.basename(camera_folder)} begun.\")\n",
    "    contours_files = sorted(\n",
    "        glob.glob(os.path.join(camera_folder, 'contours-compressed-*.npy'))\n",
    "    )\n",
    "    if contours_files:\n",
    "        contours_files = contours_files[1:]\n",
    "        centers = np.load(os.path.join(camera_folder, 'centers.npy'), allow_pickle=True)\n",
    "        sizes = np.load(os.path.join(camera_folder, 'size.npy'), allow_pickle=True)\n",
    "        tracks_file = os.path.join(camera_folder, f'first_frame_{first_frame}_max_val_{max_frame}_raw_tracks.npy')\n",
    "        raw_tracks = kbf.find_tracks(first_frame, centers, contours_files=contours_files, \n",
    "                                     sizes_list=sizes, tracks_file=tracks_file,\n",
    "                                     max_frame=max_frame)\n",
    "    else:\n",
    "        print(\"Missing contour files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_dicts = []\n",
    "for camera_folder in n_camera_folders:\n",
    "    # To speed up processing, detections found in each observation are split\n",
    "    # into 10 groups by time with 15 seconds of overlap in each group\n",
    "    centers_file = os.path.join(camera_folder, 'centers.npy')\n",
    "    centers = np.load(centers_file, allow_pickle=True)\n",
    "    max_vals = np.linspace(0, len(centers), 10, dtype=int)[1:].tolist()\n",
    "    max_vals[-1] = None\n",
    "    min_vals = np.linspace(0, len(centers), 10, dtype=int)[:-1]\n",
    "    # 15 second overlap\n",
    "    min_vals[1:] = min_vals[1:] - 450\n",
    "    for min_val, max_val in zip(min_vals, max_vals):\n",
    "        min_val = np.max([min_val, 0])\n",
    "        camera_dict = {'camera_folder': camera_folder,\n",
    "                       'first_frame': min_val,\n",
    "                       'max_frame': max_val}\n",
    "        if max_val is None:\n",
    "            tracks_basename = f'first_frame_{min_val:06d}_max_val_{max_val}_raw_tracks.npy'\n",
    "        else:\n",
    "            tracks_basename = f'first_frame_{min_val:06d}_max_val_{max_val:06d}_raw_tracks.npy'\n",
    "        tracks_file = os.path.join(camera_folder, tracks_basename)\n",
    "        if not os.path.exists(tracks_file):\n",
    "            print(tracks_file)\n",
    "            camera_dicts.append(camera_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=5) as pool:\n",
    "    pool.map(track, camera_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now connect the 10 sections of the observation that were tracked seperately together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_overlapping_tracks(observation_folder, first_group=0, last_group=None, save=False):\n",
    "    track_files = glob.glob(os.path.join(observation_folder, 'first_frame*.npy'))\n",
    "    track_files = sorted(track_files, key=lambda f: int(f.split('_')[-6]))\n",
    "\n",
    "    track_groups = []\n",
    "    for file in track_files:\n",
    "        track_groups.append(np.load(file, allow_pickle=True))\n",
    "        \n",
    "        \n",
    "    for track_file in track_files:\n",
    "        print(os.path.basename(track_file))\n",
    "        \n",
    "    first_overlap_frames = [int(f.split('_')[-6]) for f in track_files[1:]]\n",
    "    first_overlap_frames.append(None)\n",
    "    print(first_overlap_frames)\n",
    "        \n",
    "    all_tracks = []\n",
    "\n",
    "    total_tracks = 0\n",
    "    for group_ind, track_group in enumerate(track_groups[first_group:last_group]):\n",
    "        if group_ind >= len(track_groups) -1:\n",
    "            for track in track_group:\n",
    "                if type(track['track']) == list:\n",
    "                    track['track'] = np.stack(track['track'])\n",
    "                    track['pos_index'] = np.stack(track['pos_index'])\n",
    "                    if 'size' in track:\n",
    "                        track['size'] = np.stack(track['size'])\n",
    "                all_tracks.append(track)\n",
    "            total_tracks += len(track_group)\n",
    "            break\n",
    "\n",
    "        for track_ind, track in enumerate(track_group):\n",
    "            if track['first_frame'] < first_overlap_frames[first_group + group_ind]:\n",
    "                all_tracks.append(track)\n",
    "\n",
    "\n",
    "    all_tracks_file = os.path.join(observation_folder, 'raw_tracks.npy')\n",
    "    if save:\n",
    "        np.save(all_tracks_file, all_tracks)\n",
    "        print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_folders = []\n",
    "for folder in camera_folders:\n",
    "    if not os.path.exists(os.path.join(folder, 'raw_tracks.npy')):\n",
    "        observation_folders.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in observation_folders:\n",
    "    combine_overlapping_tracks(folder, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
